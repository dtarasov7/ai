
# RAG: Генерация, дополненная поиском

## Основы RAG

### Что такое RAG
- Интеграция LLM с внутренними данными компании
- Использование мощи LLM + корпоративные знания
- Делает новые данные доступными для LLM
- Преодолевает ограничения обучающих данных

### Мотивация использования
- LLM не видели личные данные компании
- Ограниченная способность работать с корпоративными данными
- Необходимость доступа к недавним данных
- Увеличение ценности извлечения из данных

## Преимущества RAG

### Точность и релевантность
- Извлечение информации в реальном времени
- Основа на существующих знаниях модели
- Использование актуальных данных
- Снижение галлюцинаций

### Настройка
- Адаптация к конкретной предметной области
- Точное соответствие информации и стилю
- Целенаправленные ответы
- Специфичность для конкретных потребностей

### Гибкость
- Различные источники данных
  - Структурированные данные
  - Неструктурированные данные
  - Базы данных
  - Веб-страницы
  - Документы
- Возможность обновления источников
- Адаптация к изменяющимся ландшафтам

### Расширение знаний
- Доступ к информации вне обучающих данных
- Расширение базы знаний без переобучения
- Универсальность моделей
- Адаптация к новым темам

## Проблемы RAG

### Качество данных
- Принцип: "мусор на входе, мусор на выходе"
- Зависимость от качества извлекаемых данных
- Проблемы устаревшей информации
- Предвзятость и неточности

### Обработка данных
- Данные в неудобной форме
- Необходимость обработки PDF-выписок
- Требуется преобразование форматов
- Подготовка для конвейера RAG

### Вычислительные издержки
- Множество новых этапов обработки
- Извлечение, обработка, интеграция данных
- Несколько вызовов LLM
- Увеличение времени ответа
- Баланс точности и ресурсов

### Сложность интеграции
- Данные в нескольких формах
- Векторы в векторных базах данных
- Подключение различных источников
- Механизмы векторного поиска
- Поддержка во времени

### Информационная перегрузка
- Извлечение слишком большого объема информации
- Необходимость фильтрации
- Механизмы ранжирования
- Определение релевантности

### Галлюцинации
- Одна из самых больших проблем
- Необходимость выявления
- Необходимость устранения
- Тщательное тестирование

### Сложность системы
- Высокий уровень сложности
- Множество компонентов
- Взаимодействие компонентов
- Оптимизация каждого компонента
- Обширное тестирование

## Словарь RAG

### LLM (Большие языковые модели)
- Генеративный ИИ для текста
- Примеры
  - OpenAI ChatGPT
  - Meta Llama
  - Google Gemini
  - Anthropic Claude
- Применимо к другим модальностям
  - Изображения
  - Аудио
  - Видео

### Промты
- **Промт**: запрос к LLM
- **Дизайн промта**: стратегия разработки промта
- **Промт-инжиниринг**: технические аспекты улучшения результата

### Фреймворки

#### LangChain
- Открытый исходный код
- 15+ миллионов загрузок ежемесячно
- Модульный и гибкий
- Конвейерный подход
- Эффективная разработка RAG

#### LlamaIndex
- Альтернатива LangChain
- Ориентация на поиск
- Извлечение данных
- Работа с большими наборами данных

### Вывод (Inference)
- Генерация выходных данных LLM
- Прогнозы на основе входных данных
- Использование предобученной модели
- Процесс предоставления ответа

### Контекстное окно

#### Определение
- Максимальное количество токенов
- Обработка за один проход
- Фиксируется при обучении
- Связано с входным размером

#### Обработка длинных текстов
- Разделение на сегменты
- Раздвижные окна
- Усечение текста

#### Влияние на модель
- Понимание зависимостей
- Поддержание контекста
- Согласованность ответов
- Вычислительные ресурсы

#### Размеры окон популярных LLM
- Старые модели: меньшие окна (4-8K токенов)
- Современные модели: большие окна
- Gemini 1.5: 1 миллион токенов
- Тенденция к росту

#### Значение для RAG
- Определяет объем извлекаемой информации
- Влияет на формирование ответа
- Критический параметр эффективности

### Тонкая настройка

#### FMFT (Full-Model Fine-Tuning)
- Обучение базовой модели
- Новые возможности
- Обновление всех параметров
- Обновление всех смещений

#### PEFT (Parameter-Efficient Fine-Tuning)
- Фокус на определенных частях
- Аналогичные результаты FMFT
- Меньше затрат
- Меньше времени
- Меньше данных

#### Применение
- Больше знаний из области
- Специфический стиль речи
- Научная область
- Юридическая сфера

### Векторные хранилища

#### Определения
- **Векторное хранилище**: общий термин
- **Векторная база данных**: подтип хранилища
- Все БД - хранилища, но не наоборот

#### В LangChain
- Общий термин: векторные хранилища
- Охват всех способов хранения
- Не все - полноценные БД
- Большинство называют БД

### Векторы (Эмбеддинги)

#### Определение
- Математическое представление данных
- В NLP и LLM называются эмбеддингами
- Ключевое понятие для RAG

#### Структура
- Определенная размерность
- Пример: [0.123, 0.321, 0.312, 0.231]
- Массивы NumPy (не списки Python)
- Сотни или тысячи измерений

#### NumPy преимущества
- Оптимизация для ML
- Быстрая обработка данных
- Стандарт для эмбеддингов
- Векторизованные операции
- Совместимость (SciPy, pandas, TensorFlow, PyTorch)

#### Размерность
- Более высокая = больше деталей
- Захват семантической информации
- Критично для точного сопоставления
- Важно для приложений RAG

## Применение RAG

### Поддержка клиентов
- Чат-боты с RAG
- Прошлые взаимодействия
- FAQ и справочные документы
- Специфичная информация о клиенте

### Техническая поддержка
- Доступ к истории клиентов
- Улучшенные чат-боты
- Информация о проблемах

### Автоматизированная отчетность
- Создание черновиков
- Обобщение статей
- Исследовательские работы
- Удобоваримые форматы

### Электронная коммерция
- Динамические описания продуктов
- Пользовательский контент
- Рекомендации продуктов

### Базы знаний
- Улучшенный поиск
- Генерация резюме
- Прямые ответы на запросы
- Различные области
  - Юриспруденция
  - Исследования
  - Медицина
  - Патенты
  - Техническая документация

### Поиск инноваций
- Сканирование качественных источников
- Обобщение информации
- Определение трендов
- Потенциальные области инноваций

### Обучение и образование
- Создание учебных материалов
- Адаптация к потребностям учащихся
- Уровень знаний
- Включение внутренних знаний организации
- Индивидуальные потребности

## Сравнения

### RAG vs Генеративный ИИ

#### Обычный генеративный ИИ
- Революционное изменение
- Рост производительности
- Применения
  - Бизнес-планы
  - Написание кода
  - Маркетинговые тексты
  - Рецепты
- Ограничение: не знает внутренних данных

#### RAG преимущество
- Доступ ко всем корпоративным данным
- История компании
- Данные о клиентах
- Взаимодействия
- Продукты и услуги
- Потребности клиентов

### RAG vs Тонкая настройка

#### Два способа адаптации LLM

##### Тонкая настройка
- Корректировка весов/смещений
- Прямое влияние на модель
- Постоянное изменение
- Новые обучающие данные

##### Промт (RAG)
- Расширенный промт
- Введение новых знаний
- Модель действует на основе знаний

#### Когда использовать

##### Тонкая настройка лучше для
- Специализированные задачи
- Обучение стилю общения
- Адаптация к домену
- Менее надежна для фактов

##### RAG лучше для
- Извлечение фактов
- Отсутствующая информация
- Конфиденциальные данные
- Динамическая интеграция
- Не изменяет веса модели

#### Аналогия с памятью
- **Тонкая настройка**: долговременная память
  - Понимание контекста
  - Забывание деталей
- **RAG (промт)**: кратковременная память
  - Свежие факты
  - Детали доступны
  - Порядок формулировок

#### Компромиссы
- Тонкая настройка: все данные
- RAG: ограничение контекстным окном
- Проблема "иголка в стоге сена"
- Эволюция контекстных окон

#### Токены vs Слова
- Токены ≠ слова
- Включают пунктуацию
- Символы и цифры
- Зависит от токенизации
- Пример: "мороженое" = 2 токена

## Архитектура систем RAG

### Пользовательский процесс

#### Шаги
1. Пользователь вводит запрос
2. Приложение проверяет данные
3. Определяет релевантные данные
4. Предоставляет ответ с использованием данных RAG

### Технические этапы

#### 1. Индексирование (до запроса)
- Преобразование данных в векторы
- Сохранение в векторной БД
- Оптимизация поиска
- Повышение скорости и эффективности

#### 2. Извлечение (Retrieval)
- Векторизация запроса пользователя
- Передача в векторный поиск
- Извлечение релевантных данных
- Возврат результатов с ключами
- Извлечение исходного содержимого
- Получение нескольких документов

#### 3. Генерация (Generation)
- Фильтрация/обработка данных
- Передача в LLM
- Прикрепление промта
- Инструкции для LLM
  - "Вы полезный помощник"
  - "Используйте эту информацию"
  - "Если не знаете - скажите"
- Обработка запроса
- Предоставление ответа

### Три основных стадии
1. **Индексирование**
2. **Извлечение**
3. **Генерация**
