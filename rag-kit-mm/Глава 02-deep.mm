# MindMap: Полный конвейер RAG (Глава 2)

## Введение
- Основа для всего кода в книге
- Создание полного конвейера RAG
- Постепенное улучшение кода в последующих главах

## Технические требования
- Код доступен в репозитории
- Требуется среда Jupyter Notebook
- Python 3
- Различные варианты настройки среды:
  - Google Colab
  - Docker Desktop + Kubernetes
  - Локальные установки

## Компоненты конвейера RAG

### Настройка LLM (OpenAI)
- Создание учетной записи OpenAI
- Получение API ключа
- Типы разрешений ключа:
  - Все
  - Ограниченный
  - Только чтение
- Управление кредитами и расходами

### Установка пакетов Python
```python
%pip install langchain_community
%pip install langchain_experimental
%pip install langchain-openai
%pip install langchainhub
%pip install chromadb
%pip install langchain
%pip install beautifulsoup4
```

### Импорт библиотек
- os - работа с ОС
- WebBaseLoader - загрузчик веб-страниц
- bs4 - парсинг HTML
- openai - API OpenAI
- ChatOpenAI, OpenAIEmbeddings - модели и эмбеддинги
- hub - готовые компоненты
- StrOutputParser - парсер вывода
- RunnablePassthrough - пропуск данных
- chromadb - векторная БД
- Chroma - интерфейс к Chroma DB
- SemanticChunker - семантическое разделение текста

### Подключение OpenAI
- Установка API ключа
- Использование для ChatGPT и сервиса эмбеддингов
- Предупреждение о безопасности

## Этап индексирования

### Загрузка веб-страниц
- WebBaseLoader для загрузки документов
- Параметры:
  - web_paths - URL адреса
  - bs_kwargs - аргументы BeautifulSoup
  - parse_only - фильтрация элементов HTML
- Извлечение текста и метаданных

### Разделение текста (Splitting)
- SemanticChunker для семантического разделения
- Преимущества:
  - Сохранение контекста
  - Семантическая связность
- Альтернативы: RecursiveCharacterTextSplitter
- Стоимость обработки эмбеддингов

### Эмбеддинг и индексирование
- Chroma DB как векторное хранилище
- OpenAIEmbeddings для создания векторных представлений
- Создание vectorstore и retriever
- Тестирование поиска релевантных документов

## Этап поиска и генерации

### Шаблоны промтов
- LangChain Hub как репозиторий компонентов
- Извлечение промта "jclemens24/rag-prompt"
- Структура промта:
  - Роль ассистента
  - Использование контекста
  - Формат вопрос-контекст-ответ

### Форматирование документов
- Функция format_docs для преобразования в строку
- Объединение page_content с разделителями
- Подготовка данных для промта

### Определение LLM
- ChatOpenAI с моделью "gpt-40-mini"
- Параметр temperature=0
- Возможность использования других моделей

### Создание цепочки LCEL
```python
rag_chain = (
    {"context": retriever | format_docs,
     "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
```
- Компоненты цепочки:
  - Извлечение и форматирование контекста
  - Передача вопроса без изменений
  - Заполнение промта
  - Генерация ответа LLM
  - Парсинг вывода

### Запуск конвейера
- rag_chain.invoke() с пользовательским вопросом
- Пример: "What are the advantages of using RAG?"
- Получение форматированного ответа

## Полный код конвейера
- Все этапы от установки до выполнения
- Обработка ошибок и дополнительные зависимости
- Необходимость перезагрузки ядра

## Заключение
- Базовый конвейер RAG готов к использованию
- Возможности для оптимизации и улучшения
- Решение проблем RAG в последующих главах
