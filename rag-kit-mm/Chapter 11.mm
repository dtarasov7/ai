
# LangChain для улучшения RAG

## Загрузчики документов (11.1)

### Назначение
- Доступ к данным
- Извлечение и загрузка
- Конвертация в формат для индексации

### Установка пакетов
- bs4 (Beautiful Soup 4)
- python-docx
- docx2txt
- jq (процессор JSON)

### Типы загрузчиков

#### HTML Loader
- BSHTMLLoader
- Работа с локальными HTML-файлами
- Парсинг через BeautifulSoup

#### PDF Loader
- PdfReader (PyPDF2)
- Альтернативы
  - PyPDF
  - PyMuPDF
  - MathPix
  - Unstructured
  - AzureAIDocumentIntelligence
  - UpstageLayoutAnalysis

#### Microsoft Word Loader
- Docx2txtLoader
- Обработка .docx файлов
- Извлечение текста

#### JSON Loader
- JSONLoader
- jq_schema для навигации
- Работа с JSON-объектами

### Метаданные
- Автоматическое добавление
- Источник документа
- ID документа
- Необходимость обработки конфликтов

## Текстовые сплиттеры (11.2)

### Проблемы больших документов
- Потеря информации при векторизации
- Ограничения моделей эмбеддингов
  - OpenAI: 8191 токен
- Необходимость разбиения

### Символьный сплиттер (CharacterTextSplitter)

#### Параметры
- separator (разделитель)
  - По умолчанию: \n\n
  - Рекомендуется: \n
- chunk_size (размер фрагмента)
  - До N символов
- chunk_overlap (перекрытие)
  - Сохранение контекста
- is_separator_regex
  - Использование регулярных выражений

#### Недостатки
- Разрезает текст посреди предложений
- Не учитывает смысловую структуру
- Требует ручной настройки разделителя

### Рекурсивный символьный сплиттер

#### Преимущества
- Рекомендуется LangChain
- Сохраняет связанные фрагменты
- Логичное разбиение

#### Список разделителей
- "\n\n" (абзацы)
- "\n" (строки)
- ". " (предложения)
- " " (слова)
- "" (символы)

#### Алгоритм работы
- Поиск точки разбиения
  - В диапазоне [chunk_size - chunk_overlap, chunk_size]
- Разбиение на границах слов/строк
- Рекурсивное применение к остатку

#### Ограничения
- Не учитывает семантические связи
- Ориентируется только на разделители

### Семантический сплиттер (SemanticChunker)

#### Особенности
- Экспериментальный метод
- Автоматическое определение границ
- Без ручной настройки chunk_size

#### Принцип работы
- Разбиение на предложения
- Группировка по 3 предложения
- Объединение семантически схожих групп
- Использование эмбеддингов

#### Параметры
- embedding_function
  - Модель для эмбеддингов
- number_of_chunks
  - Количество итоговых фрагментов
  - Больше = мельче фрагменты

#### Когда работает хуже
- Много кода в тексте
- Адреса и имена
- Внутренние идентификаторы
- Низкая семантическая значимость

#### Преимущества
- Учет смысла текста
- Хорошие результаты на обычных текстах

### Техника скользящего окна
- Перекрытие фрагментов
- Сохранение контекста на границах
- Аналогия с CNN

### Инструменты тестирования
- ChunkViz (Грег Камрадт)
- Визуализация работы сплиттеров
- Сравнение методов

## Парсеры выходных данных (11.3)

### Назначение
- Структурирование ответов LLM
- Форматирование результатов
- Передача на следующий этап

### Парсер строкового вывода

#### Характеристики
- Базовый парсер
- StrOutputParser
- Передача строкового результата
- Использование в простых случаях

#### Применение
- В цепочках обработки
- Присвоение переменной для повторного использования

### Парсер JSON-вывода

#### Компоненты
- JsonOutputParser
- BaseModel (Pydantic)
- Field (описание полей)
- Generation (объект вывода)

#### Определение структуры
- FinalOutputModel
  - relevance_score (float)
  - answer (string)
- Расширяемая модель

#### Функции обработки

##### format_json_output
- Создание словаря
- Использование extract_score
- json.dumps для преобразования
- Парсинг через json_parser

##### conditional_answer
- Проверка relevance_score
- Возврат "I don't know" если < 4
- Форматирование JSON при релевантности

#### Интеграция в цепочку
- RunnableParallel
- RunnablePassthrough
- Объединение цепочек
- str_output_parser для промежуточных результатов
- JSON-парсер в conditional_answer

#### Ограничения
- Сложность гарантировать формат от LLM
- Необходимость дополнительных проверок
- Легковесный слой форматирования

## Общие концепции

### LangChain Expression Language (LCEL)
- Специфичный язык выражений
- Построение цепочек обработки

### Объекты Document
- Хранение текста
- create_documents для подготовки
- split_text для простого текста

### Метаданные
- id (идентификатор)
- search_source (источник поиска)
- source (источник документа)

### Векторное хранилище
- dense_documents
- sparse_documents
- Индексирование фрагментов

### Практические рекомендации
- Тестирование разных методов
- Изменение параметров
- Исследование влияния на результаты
- Выбор подходящего метода для проекта

## Следующие шаги
- LangGraph
- AI-агенты
- Более сложные архитектуры
