# RAG (Retrieval-Augmented Generation)

## Основы и принципы
- Позволяет LLM работать с внутренними данными компании
- Решает проблему отсутствия доступа LLM к приватным или новым данным
- Сочетает мощь LLM с корпоративными знаниями

## Преимущества
### Повышенная точность и релевантность
- Использование актуальных данных в реальном времени
- Основа ответов: знания модели + предоставленные данные

### Настройка и адаптация
- Адаптация к конкретной предметной области
- Соответствие информации и стиля потребностям компании

### Гибкость источников данных
- Работа со структурированными и неструктурированными данными
- Возможность обновления и замены источников

### Расширение знаний модели
- Преодоление ограничений обучающих данных
- Доступ к информации вне исходного обучения

### Устранение галлюцинаций
- Снижение риска выдачи неверной информации
- Возможность проверки и фильтрации ответов

## Проблемы и вызовы
### Зависимость от качества данных
- "Мусор на входе - мусор на выходе"
- Риск устаревшей, предвзятой или неточной информации

### Обработка и очистка данных
- Необходимость преобразования в полезный формат
- Сложности работы с PDF и другими форматами

### Вычислительные издержки
- Дополнительные этапы обработки
- Увеличение времени ответа
- Влияние на эффективность и масштабируемость

### Сложность интеграции
- Множество форматов и расположений данных
- Необходимость технических знаний и инфраструктуры

### Информационная перегрузка
- Риск извлечения слишком большого объема информации
- Необходимость фильтрации и ранжирования

### Сложность тестирования и оптимизации
- Множество взаимодействующих компонентов
- Необходимость тщательного тестирования каждого элемента

## Ключевые понятия и термины
### LLM (Большие языковые модели)
- ChatGPT (OpenAI)
- Llama (Meta)
- Gemini (Google)
- Claude (Anthropic)

### Промты и инжиниринг
- Промт: отправка запроса LLM
- Дизайн промтов: стратегия разработки
- Промт-инжиниринг: технические аспекты улучшения результатов

### Фреймворки
- LangChain: популярный фреймворк с открытым исходным кодом
- LlamaIndex: альтернатива с фокусом на поиске и извлечении

### Вывод (Inference)
- Процесс генерации ответов на основе входных данных
- Использование предварительно обученной модели

### Контекстное окно
- Максимальное количество токенов для обработки за один проход
- Влияет на способность понимать контекст
- Примеры размеров:
  - ChatGPT-3.5: 4,096-16,385
  - ChatGPT-4: 8,192-128,000
  - Claude 3: 200,000
  - Gemini 1.5: 1,000,000

### Тонкая настройка
- Полная настройка (FMFT): обновление всех параметров
- Параметроэффективная настройка (PEFT): фокус на части параметров

### Векторные хранилища и базы данных
- Векторное хранилище: общий термин для хранения векторов
- Векторная база данных: полнофункциональная БД для векторов

### Векторы и эмбеддинги
- Математическое представление данных
- Захват семантической информации
- Высокая размерность для детального представления
- Использование NumPy для эффективной работы

## Практические применения
### Поддержка клиентов и чат-боты
- Интеграция с историей взаимодействий
- Доступ к FAQ и справочным документам

### Техническая поддержка
- Улучшение доступа к информации о клиентах
- Повышение эффективности чат-ботов

### Автоматизированная отчетность
- Создание проектов и обобщение данных
- Работа с неструктурированными данными

### Электронная коммерция
- Динамические описания продуктов
- Персонализированные рекомендации

### Базы знаний
- Улучшение поиска и полезности
- Генерация резюме и прямых ответов
- Применение в юриспруденции, медицине, исследованиях

### Поиск инноваций
- Сканирование и обобщение информации
- Выявление тенденций и возможностей

### Обучение и образование
- Создание адаптированных материалов
- Интеграция внутренних знаний организации

## Сравнение с другими подходами
### Обычный генеративный ИИ
- Не знает внутренних данных компании
- Ограничен обучающими данными
- RAG добавляет доступ ко всем корпоративным данным

### Тонкая настройка модели
- Изменение весов и смещений модели
- Эффективна для специализированных задач
- RAG лучше для запоминания фактов
- RAG менее затратен computationally

## Архитектура RAG
### Основные этапы
#### Индексирование (до запроса)
- Преобразование данных в векторы
- Сохранение в векторной БД
- Оптимизация поиска

#### Извлечение (retrieval)
- Векторизация пользовательского запроса
- Поиск релевантных данных в векторной БД
- Возврат уникальных ключей и исходного содержимого

#### Генерация
- Передача данных в LLM с промтом
- Формирование ответа на основе внешних данных
- Обработка случаев отсутствия информации

### Техническая реализация
- Два основных этапа кодирования: извлечение и генерация
- Индексирование выполняется предварительно
- Режим реального времени или подготовленные данные
