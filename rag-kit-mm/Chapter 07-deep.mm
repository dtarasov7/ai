# Глава 7: Ключевая роль векторов и векторных хранилищ в RAG

## Основы векторов в RAG
- Векторы vs эмбеддинги
  - Эмбеддинги - специфический тип векторного представления
  - Термины используются как синонимы в контексте LLM и RAG
- Свойства векторов
  - Размерность (1536 для OpenAIEmbeddings)
  - Точность представления (64-битные числа с плавающей точкой)
  - Формат данных (списки Python vs массивы NumPy)
- Квантование
  - Преобразование в формат с меньшей точностью
  - Снижение требований к памяти и вычислениям
  - Компромисс: потеря информации vs эффективность

## Где в коде скрываются векторы
- Векторизация в двух местах:
  - Исходные данные для RAG
  - Пользовательские запросы
- Ключевые строки кода:
  - `vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())`
  - `retriever = vectorstore.as_retriever()`
- Процесс поиска
  - Сравнение эмбеддинга запроса с эмбеддингами в хранилище
  - Математические операции для измерения расстояния

## Объем текста и векторизация
- Разный объем → одинаковая размерность
- Баланс размера фрагмента:
  - Большие фрагменты → "размытые" эмбеддинги
  - Малые фрагменты → меньше контекста для сопоставления
- Semantic Chunker для интеллектуального разбиения

## Качество семантических моделей
- Не все алгоритмы векторизации одинаково эффективны
- Специализированные модели для конкретных областей
- Дообучение моделей эмбеддингов
- Эволюция понимания контекста и нюансов

## Лаборатория кода 7.1 - Методы векторизации
### TF-IDF (1972)
- Статистический подход
- Разреженные векторы
- Обучение на данных
- Пример с шекспировскими пьесами

### Word2Vec, Doc2Vec, Sentence2Vec
- Нейросетевые модели
- Учет контекста слов
- Обучение без учителя
- Векторные представления разных уровней

### BERT (Трансформеры)
- Механизм самовнимания
- Предварительное обучение на больших данных
- Локальное использование vs облачные API
- Возможность дообучения

### OpenAI и облачные сервисы
- Масштаб моделей (миллиарды параметров)
- Матрешечные эмбеддинги
- Адаптивный поиск
- Альтернативные провайдеры: GCP, AWS, Cohere

## Факторы выбора векторизации
### Качество эмбеддингов
- Тестирование на конкретных данных
- MTEB benchmark как ориентир
- Важность доменной специфики

### Стоимость
- От бесплатных до коммерческих моделей
- Масштабирование затрат
- Локальные модели vs облачные API

### Доступность сети
- Зависимость от облачных сервисов
- Резервные стратегии
- Локальные модели для офлайн-работы

### Скорость
- Сетевая задержка vs локальная обработка
- Время вывода модели
- Пакетная генерация

### Совместимость
- Уникальные векторные сигнатуры моделей
- Невозможность сравнения разных моделей
- Затраты на смену модели

## Векторные хранилища
### Архитектура
- Слой индексации (деревья, хэширование)
- Слой хранения (диск/память)
- Слой обработки (опционально)

### Популярные решения
#### Chroma
- Открытый исходный код
- Простота использования
- Локальное развертывание

#### LanceDB
- Гибридный поиск
- Поддержка различных метрик
- Эффективный поиск соседей

#### Milvus
- Масштабируемость
- Облачно-ориентированная архитектура
- Мультивекторная индексация

#### Pgvector
- Расширение PostgreSQL
- Интеграция с реляционными данными
- Зрелая экосистема

#### Pinecone
- Полностью управляемый сервис
- Индексирование в реальном времени
- Минимальные настройки

#### Weaviate
- Поисковый движок с открытым кодом
- Подход на основе схем
- GraphQL API

## Выбор векторного хранилища
### Критерии выбора
- Совместимость с инфраструктурой
- Масштабируемость и производительность
- Простота использования и обслуживания
- Безопасность и соответствие требованиям
- Стоимость и лицензирование
- Экосистема и интеграции

### Рекомендации
- Оценка долгосрочных последствий
- Регулярный пересмотр выбора
- Соответствие архитектуре системы
- Учет роста и изменения требований
