Буду рад подготовить для тебя полноценный обучающий курс по MCP и Python! Model Context Protocol (MCP) — это открытый стандарт от Anthropic, введённый в ноябре 2024 года, для унифицированной интеграции LLM-приложений с внешними источниками данных и инструментами через JSON-RPC 2.0. Протокол поддерживается крупными AI-провайдерами, включая OpenAI и Google DeepMind.[1][2]

Ниже приведён полный репозиторий курса с лекциями, диаграммами, примерами кода и практическими заданиями.

***

## Структура репозитория

```
mcp-python-course/
├── README.md
├── requirements.txt
├── .gitignore
├── lectures/
│   ├── module01_introduction.md
│   ├── module02_protocol.md
│   ├── module03_python_sdk.md
│   ├── module04_debugging.md
│   ├── module05_llm_host.md
│   ├── module06_model_integration.md
│   └── module07_practice.md
├── diagrams/
│   ├── architecture.puml
│   ├── message_flow.puml
│   ├── transport_comparison.puml
│   └── mindmap.puml
├── examples/
│   ├── simple_server_stdio.py
│   ├── simple_server_http.py
│   ├── simple_client_stdio.py
│   ├── simple_client_http.py
│   ├── async_tools_example.py
│   ├── progress_notifications.py
│   └── system_prompts/
│       ├── non_finetuned_tool_usage.txt
│       └── structured_output.txt
├── labs/
│   ├── lab01_basic_server/
│   │   ├── README.md
│   │   └── solution/
│   ├── lab02_resources_prompts/
│   │   ├── README.md
│   │   └── solution/
│   ├── lab03_async_tools/
│   │   ├── README.md
│   │   └── solution/
│   ├── lab04_http_transport/
│   │   ├── README.md
│   │   └── solution/
│   ├── lab05_progress/
│   │   ├── README.md
│   │   └── solution/
│   └── lab06_full_integration/
│       ├── README.md
│       └── solution/
└── utils/
    ├── logger.py
    └── helpers.py
```

***

## Содержимое файлов

### `README.md`

```markdown
# Курс "Model Context Protocol (MCP) и Python"

Добро пожаловать в обучающий курс по Model Context Protocol (MCP) и его реализации на Python!

## О курсе

Этот курс предназначен для разработчиков, желающих освоить MCP — открытый протокол для стандартизированной интеграции LLM-приложений с внешними системами, инструментами и данными.

## Структура курса

### Модули

1. **Введение в MCP** - основы протокола, архитектура, роль в экосистеме LLM
2. **MCP-протокол** - транспорты, типы сообщений, возможности клиента и сервера
3. **MCP SDK на Python** - работа с официальным SDK, реализация клиентов и серверов
4. **Отладка и мониторинг** - логирование, диагностика проблем
5. **LLM-хост** - взаимодействие с хостом приложения
6. **Интеграция с моделями** - fine-tuned модели и работа через системные промпты
7. **Практика** - комплексная разработка MCP-решений

### Лабораторные работы

- Lab 01: Базовый MCP-сервер
- Lab 02: Resources и Prompts
- Lab 03: Асинхронные инструменты
- Lab 04: HTTP-транспорт
- Lab 05: Progress notifications
- Lab 06: Полная интеграция с LLM

## Требования

- Python 3.10+
- Базовые знания asyncio
- Опыт работы с JSON и REST API

## Установка

```bash
# Клонировать репозиторий
git clone <repository-url>
cd mcp-python-course

# Создать виртуальное окружение
python3 -m venv venv
source venv/bin/activate  # Linux/macOS
# или
venv\Scripts\activate  # Windows

# Установить зависимости
pip install -r requirements.txt
```

## Начало работы

1. Изучите лекции в папке `lectures/` по порядку
2. Просматривайте диаграммы в `diagrams/` для визуального понимания
3. Запускайте примеры из `examples/`
4. Выполняйте лабораторные работы из `labs/`

## Диаграммы

Для просмотра PlantUML диаграмм используйте:
- [PlantUML Online Server](http://www.plantuml.com/plantuml/uml/)
- VS Code расширение "PlantUML"
- IntelliJ IDEA встроенную поддержку

## Ресурсы

- [Официальная спецификация MCP](https://modelcontextprotocol.io/specification/2024-11-05)
- [MCP Python SDK на GitHub](https://github.com/modelcontextprotocol/python-sdk)
- [MCP Python SDK на PyPI](https://pypi.org/project/mcp/)

## Лицензия

Материалы курса предоставляются в образовательных целях.
```

***

### `requirements.txt`

```txt
# MCP Python SDK с CLI инструментами
mcp[cli]==1.8.0

# Async HTTP клиент для инструментов
httpx==0.28.1

# Web framework для HTTP транспорта (SSE)
starlette==0.42.0
uvicorn==0.34.0

# Утилиты для async операций
anyio==4.8.0

# Логирование
structlog==25.1.0

# Тестирование
pytest==8.3.4
pytest-asyncio==0.25.2

# Типизация
typing-extensions==4.12.2
```

***

### `.gitignore`

```gitignore
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
venv/
env/
ENV/
*.egg-info/
dist/
build/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db

# Logs
*.log

# MCP specific
.mcp/
mcp_data/
```

***

### `lectures/module01_introduction.md`

```markdown
# Модуль 1. Введение в Model Context Protocol

## Что такое MCP (Model Context Protocol)

Model Context Protocol (MCP) — это открытый протокол, представленный компанией Anthropic в ноябре 2024 года, для стандартизированного способа интеграции LLM-приложений с внешними источниками данных и инструментами.

### Ключевые возможности

MCP предоставляет стандартизированный способ для приложений:

- **Делиться контекстной информацией** с языковыми моделями
- **Предоставлять инструменты и возможности** AI-системам
- **Создавать композируемые интеграции** и рабочие процессы

### Зачем нужен MCP?

До появления MCP каждое LLM-приложение реализовывало собственные методы интеграции с внешними системами. Это приводило к:

- Дублированию кода
- Несовместимости между решениями
- Сложности поддержки множества интеграций
- Отсутствию стандартов безопасности

MCP решает эти проблемы, предоставляя **универсальный интерфейс** подобно тому, как USB-C стандартизировал подключение устройств.

## Роль MCP в экосистеме LLM

MCP действует как **посредник** между LLM-приложениями и внешними ресурсами:

```
┌─────────────┐         ┌──────────────┐         ┌──────────────┐
│   LLM       │◄────────┤  MCP Client  │◄────────┤  MCP Server  │
│ Application │         │  (в Host)    │         │  (Services)  │
│   (Host)    │         └──────────────┘         └──────────────┘
└─────────────┘                                   ┌──────────────┐
                                                  │  Databases   │
                                                  │  APIs        │
                                                  │  Files       │
                                                  │  Tools       │
                                                  └──────────────┘
```

### Участники протокола

1. **Host (Хост)** — LLM-приложение, которое инициирует подключения (например, Claude Desktop, IDE с AI)
2. **Client (Клиент)** — коннектор внутри хост-приложения, реализующий MCP-протокол
3. **Server (Сервер)** — сервис, предоставляющий контекст, данные и возможности

## Архитектура: клиент, сервер, хост

### Компоненты архитектуры

#### Host (Хост-приложение)

- Запускает LLM
- Управляет пользовательским интерфейсом
- Содержит один или несколько MCP-клиентов
- **Примеры**: Claude Desktop, Cursor IDE, продолжение беседы с AI

#### Client (MCP-клиент)

- Живёт внутри хоста
- Поддерживает соединение с одним или несколькими серверами
- Отправляет запросы серверам
- Получает ресурсы, промпты и инструменты от серверов
- Передаёт результаты хосту и LLM

#### Server (MCP-сервер)

- Независимый процесс или сервис
- Предоставляет **ресурсы** (данные, контекст)
- Предоставляет **промпты** (шаблоны взаимодействий)
- Предоставляет **инструменты** (функции для выполнения)
- Может инициировать **сэмплирование** (recursive LLM вызовы)

### Потоки данных

```
Пользователь
    │
    ▼
┌─────────────────────┐
│   Host Application  │
│  ┌──────────────┐   │
│  │ MCP Client   │   │
│  └──────┬───────┘   │
└─────────┼───────────┘
          │ JSON-RPC 2.0
          │ (stdio/HTTP/SSE)
          ▼
┌─────────────────────┐
│    MCP Server       │
│  ┌──────────────┐   │
│  │  Resources   │   │
│  │  Prompts     │   │
│  │  Tools       │   │
│  └──────────────┘   │
└─────────────────────┘
          │
          ▼
    External Systems
   (DB, API, Files)
```

### Stateful соединение

MCP использует **stateful (с состоянием) соединение**:

- Соединение устанавливается один раз при запуске
- Возможности согласовываются через `initialize`
- Состояние сохраняется между запросами
- Закрывается явно при завершении работы

### Согласование возможностей (Capability Negotiation)

При инициализации клиент и сервер обмениваются информацией о поддерживаемых возможностях:

**Возможности клиента:**
- `roots` — управление корневыми директориями
- `sampling` — возможность инициировать LLM вызовы с сервера
- `experimental` — экспериментальные возможности

**Возможности сервера:**
- `resources` — предоставление контекстных данных
- `prompts` — шаблонные сообщения
- `tools` — функции для выполнения
- `logging` — отправка логов клиенту

## Базовый протокол

### JSON-RPC 2.0

MCP использует **JSON-RPC 2.0** для всех сообщений:

```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "tools/list",
  "params": {}
}
```

### Типы сообщений

1. **Request** — запрос с ожиданием ответа
2. **Response** — ответ на запрос
3. **Error** — ошибка выполнения
4. **Notification** — одностороннее сообщение без ответа

## Резюме

MCP — это стандартизированный протокол для интеграции LLM с внешними системами через архитектуру клиент-сервер, использующий JSON-RPC 2.0 для обмена сообщениями. Протокол разделяет ответственность между хостом (LLM-приложение), клиентом (коннектор) и сервером (источник данных/инструментов).

**Следующий модуль**: детальное изучение MCP-протокола — транспорты, типы сообщений и возможности.
```

***

### `lectures/module02_protocol.md`

```markdown
# Модуль 2. MCP-протокол

## Transport (Транспортные уровни)

MCP намеренно отделяет **транспортный уровень** от формата сообщений, что позволяет использовать разные механизмы доставки в зависимости от сценария.

### Stdio Transport

**Stdio (Standard Input/Output)** — простейший транспорт для локальных серверов.

#### Как работает stdio

- Хост запускает MCP-сервер как **дочерний процесс**
- Клиент пишет JSON-сообщения в **STDIN** сервера
- Сервер отвечает через **STDOUT**
- Каждое сообщение разделяется **символом новой строки** (`\n`)

```
Client (Host)              Server (Process)
     │                           │
     │─────JSON message─────────►│ (via STDIN)
     │                           │ (обработка)
     │◄────JSON response─────────│ (via STDOUT)
     │                           │
```

#### Преимущества stdio

- Нет необходимости в портах, сокетах, SSL
- Простота отладки (можно читать логи)
- Автоматическое управление жизненным циклом процесса
- Подходит для локальных инструментов и CLI

#### Недостатки stdio

- Только локальное выполнение
- Нельзя использовать для удалённых серверов
- Сложности с бинарными данными

### HTTP/SSE Transport (Streamable HTTP)

**Server-Sent Events (SSE) over HTTP** — транспорт для удалённых серверов и облачных сервисов.

#### Как работает SSE

- Клиент устанавливает **HTTP GET** соединение к серверу на эндпоинте `/sse`
- Сервер держит соединение открытым и отправляет события через SSE
- Клиент отправляет сообщения через **HTTP POST** на `/messages/`

```
Client                    Server (HTTP/SSE)
  │                             │
  │────GET /sse────────────────►│ (открыть SSE stream)
  │                             │
  │◄───SSE event (notification)─│
  │                             │
  │────POST /messages/──────────►│ (request)
  │◄───SSE event (response)─────│
  │                             │
```

#### Преимущества HTTP/SSE

- Удалённое выполнение через сеть
- Масштабируемость (load balancing, кластеризация)
- Поддержка HTTPS и аутентификации
- Совместимость с существующей инфраструктурой

#### Недостатки HTTP/SSE

- Сложнее в настройке (порты, firewall, SSL)
- Требуется веб-сервер (uvicorn, gunicorn)
- Дополнительная задержка сети

### Сравнение транспортов

| Критерий | stdio | HTTP/SSE |
|----------|-------|----------|
| Сценарий | Локальные инструменты | Удалённые сервисы |
| Сложность | Низкая | Средняя |
| Масштабируемость | Нет | Да |
| Аутентификация | Не требуется | HTTPS, токены |
| Задержка | Минимальная | Сетевая |

## Message Types (Типы сообщений)

MCP использует четыре типа сообщений на базе JSON-RPC 2.0:

### Request (Запрос)

Сообщение, ожидающее ответа. Содержит обязательное поле `id`.

```json
{
  "jsonrpc": "2.0",
  "id": 42,
  "method": "tools/call",
  "params": {
    "name": "fetch_weather",
    "arguments": {
      "city": "Moscow"
    }
  }
}
```

**Поля:**
- `jsonrpc` — версия протокола (всегда `"2.0"`)
- `id` — уникальный идентификатор запроса (число или строка)
- `method` — имя вызываемого метода
- `params` — параметры метода (объект или массив)

### Response (Ответ)

Ответ на запрос, содержит то же `id`, что и запрос.

**Успешный ответ:**

```json
{
  "jsonrpc": "2.0",
  "id": 42,
  "result": {
    "content": [
      {
        "type": "text",
        "text": "Temperature in Moscow: -5°C"
      }
    ]
  }
}
```

**Поля:**
- `id` — совпадает с `id` запроса
- `result` — результат выполнения

### Error (Ошибка)

Ответ об ошибке выполнения запроса.

```json
{
  "jsonrpc": "2.0",
  "id": 42,
  "error": {
    "code": -32602,
    "message": "Invalid params: missing 'city' argument",
    "data": {
      "required": ["city"],
      "received": {}
    }
  }
}
```

**Поля:**
- `code` — код ошибки (стандартные JSON-RPC коды)
- `message` — читаемое описание
- `data` — дополнительная информация (опционально)

**Стандартные коды ошибок:**

| Код | Значение |
|-----|----------|
| -32700 | Parse error |
| -32600 | Invalid Request |
| -32601 | Method not found |
| -32602 | Invalid params |
| -32603 | Internal error |

### Notification (Уведомление)

Одностороннее сообщение **без ожидания ответа**. Не содержит поле `id`.

```json
{
  "jsonrpc": "2.0",
  "method": "notifications/progress",
  "params": {
    "progressToken": "abc123",
    "progress": 50,
    "total": 100,
    "message": "Processing data..."
  }
}
```

**Использование:**
- Прогресс выполнения длительных операций
- Логирование
- События без необходимости подтверждения

## Client Capabilities (Возможности клиента)

Клиент объявляет свои возможности в сообщении `initialize`.

### Roots

Позволяет серверу запрашивать список **корневых директорий**, к которым имеет доступ клиент.

```json
{
  "capabilities": {
    "roots": {
      "listChanged": true
    }
  }
}
```

**Использование:** сервер может адаптировать поведение в зависимости от файловой системы клиента.

### Sampling

Позволяет серверу **инициировать LLM-вызовы** обратно к клиенту (recursive sampling).

```json
{
  "capabilities": {
    "sampling": {}
  }
}
```

**Использование:** агентские сценарии, где сервер запрашивает у LLM дополнительную генерацию.

### Experimental

Поддержка экспериментальных возможностей.

```json
{
  "capabilities": {
    "experimental": {
      "customFeature": true
    }
  }
}
```

## Server Capabilities (Возможности сервера)

Сервер объявляет свои возможности в ответе на `initialize`.

### Resources

Сервер предоставляет **ресурсы** — контекстные данные для LLM или пользователя.

```json
{
  "capabilities": {
    "resources": {}
  }
}
```

**Методы:**
- `resources/list` — список доступных ресурсов
- `resources/read` — чтение конкретного ресурса

**Пример ресурса:**

```json
{
  "uri": "file:///project/README.md",
  "name": "Project README",
  "mimeType": "text/markdown",
  "description": "Project documentation"
}
```

### Prompts

Сервер предоставляет **шаблонные промпты** для стандартизированных взаимодействий.

```json
{
  "capabilities": {
    "prompts": {}
  }
}
```

**Методы:**
- `prompts/list` — список доступных промптов
- `prompts/get` — получение конкретного промпта

**Пример промпта:**

```json
{
  "name": "code_review",
  "description": "Review code for best practices",
  "arguments": [
    {
      "name": "code",
      "description": "Code to review",
      "required": true
    }
  ]
}
```

### Tools

Сервер предоставляет **инструменты** — функции, которые может вызывать LLM.

```json
{
  "capabilities": {
    "tools": {}
  }
}
```

**Методы:**
- `tools/list` — список доступных инструментов
- `tools/call` — вызов инструмента

**Пример инструмента:**

```json
{
  "name": "get_weather",
  "description": "Get current weather for a city",
  "inputSchema": {
    "type": "object",
    "properties": {
      "city": {
        "type": "string",
        "description": "City name"
      }
    },
    "required": ["city"]
  }
}
```

### Logging

Сервер может отправлять **логи** клиенту для отладки.

```json
{
  "capabilities": {
    "logging": {}
  }
}
```

**Уровни логов:** `debug`, `info`, `warning`, `error`

### Completions (Deprecated)

Возможность автодополнения (устарела в новых версиях).

## Utilities (Утилиты протокола)

### Cancelation (Отмена операций)

Клиент может отменить длительную операцию отправкой уведомления:

```json
{
  "jsonrpc": "2.0",
  "method": "notifications/cancelled",
  "params": {
    "requestId": 42,
    "reason": "User cancelled"
  }
}
```

Сервер должен прекратить выполнение запроса с `id=42`.

### Progress (Прогресс выполнения)

Для длительных операций сервер отправляет уведомления о прогрессе:

**Запрос с progressToken:**

```json
{
  "jsonrpc": "2.0",
  "id": 100,
  "method": "tools/call",
  "params": {
    "name": "process_large_file",
    "arguments": {
      "file": "data.csv"
    },
    "_meta": {
      "progressToken": "token-xyz"
    }
  }
}
```

**Уведомления о прогрессе:**

```json
{
  "jsonrpc": "2.0",
  "method": "notifications/progress",
  "params": {
    "progressToken": "token-xyz",
    "progress": 50,
    "total": 100,
    "message": "Processing row 5000/10000"
  }
}
```

### Ping (Проверка соединения)

Клиент или сервер может отправить ping для проверки жизнеспособности соединения:

```json
{
  "jsonrpc": "2.0",
  "id": 999,
  "method": "ping"
}
```

Ответ:

```json
{
  "jsonrpc": "2.0",
  "id": 999,
  "result": {}
}
```

## Inspector (Инструмент отладки)

MCP SDK предоставляет **Inspector** — интерактивный инструмент для тестирования серверов.

### Запуск Inspector

```bash
# Установка
pip install "mcp[cli]"

# Запуск с вашим сервером
mcp dev your_server.py
```

### Возможности Inspector

- Просмотр списка инструментов, ресурсов, промптов
- Интерактивный вызов инструментов с параметрами
- Просмотр логов и ошибок
- Тестирование JSON-схем

**Пример использования:**

1. Запустить `mcp dev server.py`
2. Открыть браузер на указанном URL
3. Выбрать инструмент `fetch` из списка
4. Ввести параметры: `{"url": "https://example.com"}`
5. Нажать Execute
6. Просмотреть результат

## Резюме

MCP-протокол использует JSON-RPC 2.0 с поддержкой двух транспортов (stdio и HTTP/SSE), четырёх типов сообщений (Request, Response, Error, Notification) и гибкого согласования возможностей между клиентом и сервером. Протокол предоставляет утилиты для отмены операций, отслеживания прогресса и отладки через Inspector.

**Следующий модуль**: работа с MCP Python SDK — реализация клиентов и серверов.
```

***

### `lectures/module03_python_sdk.md`

```markdown
# Модуль 3. MCP SDK на Python

## Обзор MCP-библиотеки для Python

MCP Python SDK — официальная реализация протокола MCP для Python, доступная на [PyPI](https://pypi.org/project/mcp/) и [GitHub](https://github.com/modelcontextprotocol/python-sdk).

### Установка

```bash
# Базовая установка
pip install mcp

# С CLI инструментами (включая Inspector)
pip install "mcp[cli]"
```

### Основные компоненты SDK

```python
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from mcp.server.lowlevel import Server
from mcp.server.stdio import stdio_server
import mcp.types as types
```

**Ключевые модули:**

- `mcp.server.lowlevel` — низкоуровневый API для создания серверов
- `mcp.client.stdio` / `mcp.client.sse` — клиенты для разных транспортов
- `mcp.types` — типы данных протокола (Tool, Resource, Prompt и т.д.)
- `mcp.server.stdio` / `mcp.server.sse` — транспортные слои для серверов

### Архитектура SDK

```
┌────────────────────────────────────┐
│      Application Layer             │
│  (ваш код: tools, resources)       │
└────────────┬───────────────────────┘
             │
┌────────────▼───────────────────────┐
│      MCP Server/Client             │
│  (обработка протокола)             │
└────────────┬───────────────────────┘
             │
┌────────────▼───────────────────────┐
│      Transport Layer               │
│  (stdio / HTTP+SSE)                │
└────────────────────────────────────┘
```

## Реализация MCP-клиента

Клиент подключается к серверу, получает список возможностей и вызывает инструменты.

### Клиент для stdio транспорта

```python
import asyncio
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

async def run_client():
    """
    Пример MCP-клиента для подключения к серверу через stdio.
    
    Клиент:
    1. Запускает серверный процесс
    2. Инициализирует соединение
    3. Получает список инструментов
    4. Вызывает инструмент
    5. Завершает соединение
    """
    
    # Параметры запуска серверного процесса
    server_params = StdioServerParameters(
        command="python",  # команда для запуска
        args=["server.py"],  # аргументы (путь к серверу)
        env=None  # переменные окружения (опционально)
    )
    
    # Создаём контекстный менеджер для stdio клиента
    async with stdio_client(server_params) as (read, write):
        # Создаём сессию клиента
        async with ClientSession(read, write) as session:
            
            # Инициализируем соединение с сервером
            await session.initialize()
            
            # Получаем список доступных инструментов
            tools_result = await session.list_tools()
            print(f"Доступные инструменты: {tools_result.tools}")
            
            # Вызываем инструмент с аргументами
            result = await session.call_tool(
                name="add",
                arguments={"a": 5, "b": 3}
            )
            
            print(f"Результат вызова add(5, 3): {result.content}")

if __name__ == "__main__":
    asyncio.run(run_client())
```

### Клиент для HTTP/SSE транспорта

```python
import asyncio
from mcp import ClientSession
from mcp.client.sse import sse_client

async def run_http_client():
    """
    Пример MCP-клиента для подключения к серверу через HTTP/SSE.
    
    Используется для подключения к удалённым серверам.
    """
    
    # URL сервера с SSE эндпоинтом
    server_url = "http://localhost:8000/sse"
    
    # Создаём SSE клиент
    async with sse_client(server_url) as (read, write):
        async with ClientSession(read, write) as session:
            
            # Инициализация
            await session.initialize()
            
            # Получаем список ресурсов
            resources_result = await session.list_resources()
            print(f"Доступные ресурсы: {resources_result.resources}")
            
            # Читаем ресурс
            if resources_result.resources:
                resource_uri = resources_result.resources.uri
                content = await session.read_resource(resource_uri)
                print(f"Содержимое ресурса: {content.contents}")

if __name__ == "__main__":
    asyncio.run(run_http_client())
```

### Обработка ошибок в клиенте

```python
from mcp.types import McpError

async def safe_tool_call(session, tool_name, arguments):
    """
    Безопасный вызов инструмента с обработкой ошибок.
    """
    try:
        result = await session.call_tool(tool_name, arguments)
        
        # Проверяем, есть ли ошибка в результате
        if result.isError:
            print(f"Инструмент вернул ошибку: {result.content}")
            return None
            
        return result.content
        
    except McpError as e:
        print(f"Ошибка протокола MCP: {e.error.message}")
        return None
    except Exception as e:
        print(f"Неожиданная ошибка: {e}")
        return None
```

## Реализация MCP-сервера

Сервер предоставляет инструменты, ресурсы и промпты клиентам.

### Базовый сервер с инструментами

```python
import asyncio
from mcp.server.lowlevel import Server
from mcp.server.stdio import stdio_server
import mcp.types as types

# Создаём экземпляр сервера с именем
app = Server("calculator-server")

@app.list_tools()
async def list_tools() -> list[types.Tool]:
    """
    Возвращает список доступных инструментов.
    
    Этот метод вызывается клиентом для обнаружения возможностей сервера.
    """
    return [
        types.Tool(
            name="add",
            description="Складывает два числа",
            inputSchema={
                "type": "object",
                "properties": {
                    "a": {
                        "type": "number",
                        "description": "Первое слагаемое"
                    },
                    "b": {
                        "type": "number",
                        "description": "Второе слагаемое"
                    }
                },
                "required": ["a", "b"]
            }
        ),
        types.Tool(
            name="multiply",
            description="Умножает два числа",
            inputSchema={
                "type": "object",
                "properties": {
                    "a": {"type": "number"},
                    "b": {"type": "number"}
                },
                "required": ["a", "b"]
            }
        )
    ]

@app.call_tool()
async def call_tool(
    name: str,
    arguments: dict
) -> list[types.TextContent | types.ImageContent | types.EmbeddedResource]:
    """
    Обрабатывает вызов инструмента.
    
    Args:
        name: Имя вызываемого инструмента
        arguments: Словарь аргументов инструмента
        
    Returns:
        Список контент-объектов с результатом
        
    Raises:
        ValueError: Если инструмент неизвестен или аргументы невалидны
    """
    
    # Валидация имени инструмента
    if name == "add":
        if "a" not in arguments or "b" not in arguments:
            raise ValueError("Отсутствуют обязательные аргументы 'a' и 'b'")
        
        result = arguments["a"] + arguments["b"]
        return [types.TextContent(type="text", text=str(result))]
        
    elif name == "multiply":
        if "a" not in arguments or "b" not in arguments:
            raise ValueError("Отсутствуют обязательные аргументы 'a' и 'b'")
        
        result = arguments["a"] * arguments["b"]
        return [types.TextContent(type="text", text=str(result))]
        
    else:
        raise ValueError(f"Неизвестный инструмент: {name}")

async def main():
    """
    Точка входа сервера.
    
    Запускает сервер с stdio транспортом.
    """
    # Создаём stdio транспорт
    async with stdio_server() as (read_stream, write_stream):
        # Запускаем сервер с опциями инициализации
        await app.run(
            read_stream,
            write_stream,
            app.create_initialization_options()
        )

if __name__ == "__main__":
    asyncio.run(main())
```

### Сервер с ресурсами

```python
@app.list_resources()
async def list_resources() -> list[types.Resource]:
    """
    Возвращает список доступных ресурсов.
    
    Ресурсы — это данные, которые могут быть использованы LLM или пользователем.
    """
    return [
        types.Resource(
            uri="config://settings",
            name="Server Settings",
            mimeType="application/json",
            description="Текущие настройки сервера"
        ),
        types.Resource(
            uri="data://stats",
            name="Statistics",
            mimeType="text/plain",
            description="Статистика использования сервера"
        )
    ]

@app.read_resource()
async def read_resource(uri: str) -> str:
    """
    Читает содержимое ресурса по URI.
    
    Args:
        uri: URI запрашиваемого ресурса
        
    Returns:
        Содержимое ресурса в виде строки
    """
    if uri == "config://settings":
        import json
        return json.dumps({
            "version": "1.0",
            "max_connections": 100,
            "timeout": 30
        }, indent=2)
        
    elif uri == "data://stats":
        return "Total calls: 42\nUptime: 3600s"
        
    else:
        raise ValueError(f"Неизвестный ресурс: {uri}")
```

### Сервер с промптами

```python
@app.list_prompts()
async def list_prompts() -> list[types.Prompt]:
    """
    Возвращает список доступных промптов.
    
    Промпты — это шаблонные сообщения для стандартизированных взаимодействий.
    """
    return [
        types.Prompt(
            name="code_review",
            description="Шаблон для ревью кода",
            arguments=[
                types.PromptArgument(
                    name="code",
                    description="Код для проверки",
                    required=True
                ),
                types.PromptArgument(
                    name="language",
                    description="Язык программирования",
                    required=False
                )
            ]
        )
    ]

@app.get_prompt()
async def get_prompt(name: str, arguments: dict) -> types.GetPromptResult:
    """
    Возвращает сгенерированный промпт с подставленными аргументами.
    
    Args:
        name: Имя промпта
        arguments: Аргументы для подстановки
        
    Returns:
        Результат с готовым промптом
    """
    if name == "code_review":
        code = arguments.get("code", "")
        language = arguments.get("language", "unknown")
        
        message = f"""Пожалуйста, проверь следующий код на {language}:

```{language}
{code}
```

Обрати внимание на:
- Соответствие best practices
- Потенциальные баги
- Производительность
- Читаемость
"""
        
        return types.GetPromptResult(
            description=f"Code review для {language}",
            messages=[
                types.PromptMessage(
                    role="user",
                    content=types.TextContent(type="text", text=message)
                )
            ]
        )
    else:
        raise ValueError(f"Неизвестный промпт: {name}")
```

### HTTP/SSE сервер

```python
from mcp.server.sse import SseServerTransport
from starlette.applications import Starlette
from starlette.routing import Route, Mount
from starlette.responses import Response
import uvicorn

def create_http_server(app: Server, port: int = 8000):
    """
    Создаёт HTTP/SSE сервер для MCP.
    
    Args:
        app: Экземпляр MCP Server
        port: Порт для прослушивания
    """
    
    # Создаём SSE транспорт с эндпоинтом для сообщений
    sse = SseServerTransport("/messages/")
    
    async def handle_sse(request):
        """
        Обработчик SSE соединения.
        
        Держит соединение открытым и отправляет события клиенту.
        """
        async with sse.connect_sse(
            request.scope,
            request.receive,
            request._send
        ) as streams:
            await app.run(
                streams,
                streams,[1]
                app.create_initialization_options()
            )
        return Response()
    
    # Создаём Starlette приложение с маршрутами
    starlette_app = Starlette(
        debug=True,
        routes=[
            Route("/sse", endpoint=handle_sse, methods=["GET"]),
            Mount("/messages/", app=sse.handle_post_message)
        ]
    )
    
    # Запускаем uvicorn
    uvicorn.run(starlette_app, host="127.0.0.1", port=port)

if __name__ == "__main__":
    app = Server("http-calculator-server")
    # ... регистрация handlers ...
    create_http_server(app, port=8000)
```

## Типы данных MCP

### Tool

```python
types.Tool(
    name="tool_name",
    description="Описание инструмента",
    inputSchema={  # JSON Schema для валидации входных данных
        "type": "object",
        "properties": {...},
        "required": [...]
    }
)
```

### Resource

```python
types.Resource(
    uri="схема://путь",  # Уникальный идентификатор ресурса
    name="Отображаемое имя",
    mimeType="text/plain",  # MIME-тип содержимого
    description="Описание ресурса"
)
```

### Prompt

```python
types.Prompt(
    name="prompt_name",
    description="Описание промпта",
    arguments=[
        types.PromptArgument(
            name="arg_name",
            description="Описание аргумента",
            required=True
        )
    ]
)
```

### Content Types

```python
# Текстовый контент
types.TextContent(type="text", text="Some text")

# Изображение (base64)
types.ImageContent(
    type="image",
    data="base64-encoded-image",
    mimeType="image/png"
)

# Встроенный ресурс
types.EmbeddedResource(
    type="resource",
    resource={...}
)
```

## Резюме

MCP Python SDK предоставляет высокоуровневый API для создания клиентов и серверов с поддержкой stdio и HTTP/SSE транспортов. Основные компоненты: `Server` для серверов, `ClientSession` для клиентов, декораторы для регистрации handlers и типизированные классы для всех объектов протокола.

**Следующий модуль**: отладка и мониторинг MCP-приложений.
```

***

### `lectures/module04_debugging.md`

```markdown
# Модуль 4. Отладка и мониторинг

## Логирование в MCP

Качественное логирование критически важно для отладки распределённых систем, таких как MCP клиент-сервер.

### Логирование на стороне сервера

MCP поддерживает отправку логов от сервера к клиенту через capability `logging`.

#### Включение logging capability

```python
from mcp.server.lowlevel import Server
import mcp.types as types
import logging

# Создаём сервер с поддержкой логирования
app = Server("my-server")

# Настраиваем Python logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@app.call_tool()
async def call_tool(name: str, arguments: dict):
    """
    Инструмент с логированием.
    """
    # Логируем вызов инструмента
    logger.info(f"Вызван инструмент '{name}' с аргументами: {arguments}")
    
    try:
        if name == "process_data":
            logger.debug("Начинаем обработку данных...")
            # ... обработка ...
            logger.debug("Обработка завершена успешно")
            return [types.TextContent(type="text", text="OK")]
            
    except Exception as e:
        logger.error(f"Ошибка при выполнении '{name}': {e}", exc_info=True)
        raise
```

#### Отправка логов клиенту

```python
from mcp.server.lowlevel import NotificationOptions

async def send_log_to_client(session, level: str, message: str):
    """
    Отправляет лог-сообщение клиенту через MCP notification.
    
    Args:
        session: Сессия MCP сервера
        level: Уровень лога (debug, info, warning, error)
        message: Текст сообщения
    """
    await session.send_log_message(
        level=level,
        logger="my-server",
        data={"message": message}
    )

# Использование в handler
@app.call_tool()
async def call_tool(name: str, arguments: dict):
    # Отправляем лог клиенту
    await send_log_to_client(session, "info", f"Executing {name}")
    
    # ... выполнение инструмента ...
```

### Структурированное логирование

Для более удобного анализа используйте `structlog`:

```python
import structlog

# Настройка structlog
structlog.configure(
    processors=[
        structlog.stdlib.add_log_level,
        structlog.stdlib.add_logger_name,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer()
    ],
    wrapper_class=structlog.stdlib.BoundLogger,
    logger_factory=structlog.stdlib.LoggerFactory(),
)

logger = structlog.get_logger()

@app.call_tool()
async def call_tool(name: str, arguments: dict):
    """
    Инструмент со структурированным логированием.
    """
    logger.info(
        "tool_called",
        tool_name=name,
        arg_count=len(arguments),
        arguments=arguments
    )
    
    # ... выполнение ...
    
    logger.info(
        "tool_completed",
        tool_name=name,
        duration_ms=42
    )
```

**Вывод:**

```json
{
  "event": "tool_called",
  "tool_name": "fetch_data",
  "arg_count": 2,
  "arguments": {"url": "https://api.example.com"},
  "timestamp": "2024-01-01T12:00:00Z",
  "level": "info"
}
```

### Логирование на стороне клиента

```python
import logging
from mcp import ClientSession

# Настраиваем логгер клиента
client_logger = logging.getLogger("mcp-client")
client_logger.setLevel(logging.DEBUG)

# Создаём handler для вывода в файл
file_handler = logging.FileHandler("mcp_client.log")
file_handler.setLevel(logging.DEBUG)
formatter = logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
file_handler.setFormatter(formatter)
client_logger.addHandler(file_handler)

async def run_client_with_logging():
    """
    Клиент с детальным логированием.
    """
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            
            client_logger.info("Инициализация соединения...")
            await session.initialize()
            client_logger.info("Соединение установлено")
            
            client_logger.debug("Запрос списка инструментов...")
            tools = await session.list_tools()
            client_logger.debug(f"Получено инструментов: {len(tools.tools)}")
            
            client_logger.info(f"Вызов инструмента 'fetch'...")
            result = await session.call_tool("fetch", {"url": "https://example.com"})
            client_logger.info(f"Инструмент выполнен, результат: {result}")
```

## Диагностика проблем

### Общие проблемы и решения

#### 1. Сервер не запускается (stdio)

**Симптомы:**
- Клиент зависает при подключении
- Timeout ошибка

**Диагностика:**

```python
import subprocess
import sys

# Проверяем, запускается ли сервер вручную
try:
    result = subprocess.run(
        ["python", "server.py"],
        capture_output=True,
        timeout=5
    )
    print("STDOUT:", result.stdout.decode())
    print("STDERR:", result.stderr.decode())
except subprocess.TimeoutExpired:
    print("Сервер не отвечает в течение 5 секунд")
except Exception as e:
    print(f"Ошибка запуска: {e}")
```

**Решения:**
- Проверьте путь к серверу
- Убедитесь, что сервер не выводит лишний текст в stdout (только JSON-RPC)
- Проверьте права на выполнение

#### 2. JSON Parse Error

**Симптомы:**
- Ошибка `-32700 Parse error`

**Причины:**
- Сервер выводит не-JSON текст в stdout
- Некорректное форматирование сообщений

**Решение:**

```python
# НЕПРАВИЛЬНО: печать отладочной информации
print("Server starting...")  # ЭТО ЛОМАЕТ ПРОТОКОЛ!

# ПРАВИЛЬНО: используйте stderr или logging
import sys
print("Server starting...", file=sys.stderr)  # В stderr — OK

# Или логируйте в файл
logger = logging.getLogger()
logger.addHandler(logging.FileHandler('server.log'))
```

#### 3. Method Not Found

**Симптомы:**
- Ошибка `-32601 Method not found`

**Причины:**
- Клиент вызывает несуществующий метод
- Сервер не зарегистрировал handler

**Решение:**

```python
# Проверьте, что handler зарегистрирован
@app.list_tools()  # Декоратор регистрирует метод
async def list_tools():
    return [...]

# Проверьте доступные методы
print(app._handlers.keys())  # Выведет список зарегистрированных handlers
```

#### 4. Invalid Params

**Симптомы:**
- Ошибка `-32602 Invalid params`

**Причины:**
- Неверные аргументы инструмента
- Несоответствие JSON Schema

**Решение:**

```python
import jsonschema

def validate_tool_arguments(arguments: dict, schema: dict):
    """
    Валидирует аргументы инструмента против JSON Schema.
    """
    try:
        jsonschema.validate(instance=arguments, schema=schema)
        return True
    except jsonschema.ValidationError as e:
        logger.error(f"Ошибка валидации: {e.message}")
        return False

@app.call_tool()
async def call_tool(name: str, arguments: dict):
    # Получаем схему инструмента
    schema = get_tool_schema(name)
    
    # Валидируем перед выполнением
    if not validate_tool_arguments(arguments, schema):
        raise ValueError("Некорректные аргументы")
    
    # ... выполнение ...
```

### Отладка транспортного уровня

#### Логирование всех JSON-RPC сообщений

```python
import json

class LoggingTransport:
    """
    Обёртка над транспортом с логированием всех сообщений.
    """
    def __init__(self, read_stream, write_stream):
        self.read = read_stream
        self.write = write_stream
        self.logger = logging.getLogger("transport")
    
    async def read_message(self):
        """Читает сообщение и логирует его."""
        message = await self.read()
        self.logger.debug(f"RECV: {json.dumps(message, indent=2)}")
        return message
    
    async def write_message(self, message):
        """Пишет сообщение и логирует его."""
        self.logger.debug(f"SEND: {json.dumps(message, indent=2)}")
        await self.write(message)
```

### Использование MCP Inspector

MCP Inspector — встроенный инструмент для интерактивной отладки серверов.

#### Запуск Inspector

```bash
# Установка с CLI инструментами
pip install "mcp[cli]"

# Запуск с вашим сервером
mcp dev server.py

# С аргументами для сервера
mcp dev server.py --port 8000 --debug
```

#### Возможности Inspector

1. **Просмотр возможностей сервера**
   - Список инструментов с их схемами
   - Список ресурсов
   - Список промптов

2. **Интерактивный вызов инструментов**
   - Выбор инструмента из списка
   - Заполнение параметров через форму
   - Просмотр результата в реальном времени

3. **Просмотр логов**
   - Все лог-сообщения от сервера
   - Фильтрация по уровню

4. **Тестирование ресурсов**
   - Чтение ресурсов по URI
   - Просмотр содержимого

### Профилирование производительности

```python
import time
from functools import wraps

def measure_time(func):
    """
    Декоратор для измерения времени выполнения async функций.
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start = time.perf_counter()
        try:
            result = await func(*args, **kwargs)
            return result
        finally:
            duration = time.perf_counter() - start
            logger.info(
                f"Function '{func.__name__}' took {duration:.3f}s",
                function=func.__name__,
                duration_ms=duration * 1000
            )
    return wrapper

@app.call_tool()
@measure_time
async def call_tool(name: str, arguments: dict):
    """
    Инструмент с измерением производительности.
    """
    # ... выполнение ...
```

### Unit-тестирование MCP серверов

```python
import pytest
from mcp.server.lowlevel import Server
import mcp.types as types

@pytest.fixture
def server():
    """Фикстура для создания тестового сервера."""
    app = Server("test-server")
    
    @app.list_tools()
    async def list_tools():
        return [
            types.Tool(
                name="test_tool",
                description="Test tool",
                inputSchema={
                    "type": "object",
                    "properties": {"value": {"type": "number"}},
                    "required": ["value"]
                }
            )
        ]
    
    @app.call_tool()
    async def call_tool(name, arguments):
        if name == "test_tool":
            return [types.TextContent(type="text", text=str(arguments["value"] * 2))]
        raise ValueError(f"Unknown tool: {name}")
    
    return app

@pytest.mark.asyncio
async def test_list_tools(server):
    """Тест получения списка инструментов."""
    # Вызываем handler напрямую
    tools = await server._handlers["tools/list"]()
    
    assert len(tools) == 1
    assert tools.name == "test_tool"

@pytest.mark.asyncio
async def test_call_tool(server):
    """Тест вызова инструмента."""
    result = await server._handlers["tools/call"](
        name="test_tool",
        arguments={"value": 21}
    )
    
    assert len(result) == 1
    assert result.text == "42"
```

## Резюме

Эффективная отладка MCP-приложений требует комплексного подхода: структурированное логирование, валидация данных, использование Inspector для интерактивного тестирования и unit-тесты для проверки корректности handlers. Логирование должно осуществляться в stderr или файлы, чтобы не нарушать JSON-RPC протокол в stdout.

**Следующий модуль**: взаимодействие с LLM-хостом.
```

***

Из-за ограничения длины ответа, я создам остальные модули, примеры кода и лабораторные работы в следующем ответе. Продолжим?

[1](https://modelcontextprotocol.io/specification/2024-11-05)
[2](https://en.wikipedia.org/wiki/Model_Context_Protocol)
[3](https://github.com/modelcontextprotocol/modelcontextprotocol)
[4](https://modelcontextprotocol.io/specification/2025-06-18)
[5](https://modelcontextprotocol.info/specification/2024-11-05/)
[6](https://github.com/ruslanmv/Simple-MCP-Server-with-Python)
[7](https://docs.roocode.com/features/mcp/server-transports)
[8](https://mcpcn.com/en/specification/2024-11-05/)
[9](https://pypi.org/project/mcp/1.8.0/)
[10](https://www.aubergine.co/insights/building-mcp-servers-using-stdio)
[11](https://github.com/modelcontextprotocol/python-sdk/blob/main/examples/servers/simple-tool/mcp_simple_tool/server.py)
[12](https://modelcontextprotocol.io/docs/develop/build-client)
[13](https://gofastmcp.com/servers/tools)
[14](https://github.com/modelcontextprotocol/python-sdk)
[15](https://openai.github.io/openai-agents-python/mcp/)
[16](https://www.reddit.com/r/mcp/comments/1piy754/3_mcp_features_you_probably_didnt_know_about/)
[17](https://discuss.huggingface.co/t/do-you-we-need-to-tell-the-llm-the-mcp-client-functions-it-can-call-in-every-prompt-or-just-system-prompt/164049)
[18](https://realpython.com/python-mcp-client/)
[19](https://github.com/cloudwalk/hermes-mcp/issues/12)
[20](https://skywork.ai/skypage/en/MCP-Server-Enhance-Prompt:-A-Deep-Dive-and-Application-Guide-for-AI-Engineers/1972486485645111296)
