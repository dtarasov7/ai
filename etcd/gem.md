Давайте разберем вашу конфигурацию по пунктам.

### 1. Насколько безопасна и надежна такая конфигурация?

**Это стандартная и рекомендуемая конфигурация для большинства кластеров (Stacked Etcd Topology).**
Если вы разворачивали кластер через `kubeadm`, то это режим по умолчанию.

*   **Надежность:** При наличии 3 мастер-нод у вас есть кворум. Etcd использует алгоритм консенсуса Raft. Для записи данных необходимо согласие (N/2)+1 узлов.
    *   3 узла = нужно 2 живых узла.
    *   Вы можете безболезненно пережить падение **одной** любой мастер-ноды. Кластер продолжит работать (и чтение, и запись).
    *   Если упадут 2 ноды — кластер встанет (потеря кворума), API перестанет отвечать на запись, но работающие поды на воркерах продолжат работать.
*   **Безопасность:** Etcd в такой конфигурации обычно слушает только localhost или внутреннюю сеть, а взаимодействие зашифровано через mTLS сертификаты. Если доступ к самим нодам ограничен, то это безопасно.

### 2. Что будет, если одновременно перезагрузятся все три мастер ноды?

Если это корректная перезагрузка (reboot), а не аварийное выключение питания (power loss) с повреждением диска:

1.  **В момент простоя:** API Kubernetes будет недоступен. Вы не сможете делать `kubectl get`, деплоить новые приложения или менять конфигурации.
2.  **Воркеры:** Поды, запущенные на рабочих узлах (worker nodes), **продолжат работать**. Трафик к приложениям будет ходить. Однако, если под упадет, он не перезапустится (так как нет связи с API). Сервисы (Service IP) и Ingress продолжат работать (так как правила iptables/ipvs уже загружены).
3.  **После включения:**
    *   Kubelet на мастерах запустит статические контейнеры (etcd, apiserver).
    *   Etcd на каждой ноде считает данные с диска.
    *   Ноды найдут друг друга (по IP-адресам, прописанным в конфигурации) и выберут лидера.
    *   API Server подключится к кластеру etcd.
    *   Работоспособность кластера восстановится автоматически.

*Риск:* Основной риск при одновременном выключении — повреждение файлов базы данных etcd (data corruption), если запись прервалась на полуслове (характерно для отключения питания). В этом случае поможет только восстановление из бэкапа.

### 3. Где хранится БД etcd?

Даже если etcd работает в контейнере, данные **обязательно** монтируются с файловой системы хоста (иначе при перезапуске контейнера данные бы исчезали).

Обычно путь по умолчанию для `kubeadm`:
`hostPath: /var/lib/etcd`

Вы можете проверить это, заглянув в манифест пода на любой мастер ноде:
```bash
cat /etc/kubernetes/manifests/etcd.yaml
```
Ищите секцию `volumes` -> `hostPath`.

### 4. Имеет ли смысл переходить на etcd под управлением systemd?

**Скорее нет, чем да.**

*   **Плюсы контейнера (Static Pod):**
    *   Этим управляет Kubelet. Если процесс упадет, Kubelet его поднимет.
    *   Обновление кластера (`kubeadm upgrade`) автоматически обновляет версию etcd одной командой.
    *   Вам не нужно возиться с systemd unit-файлами и скачиванием бинарников вручную.
*   **Минусы контейнера:** Сложнее дебажить "внутри", если имидж урезан (как вы заметили).

Переход на внешний (external) etcd или systemd имеет смысл только в очень крупных инсталляциях (сотни/тысячи нод), где ресурсы etcd нужно изолировать от Control Plane, чтобы нагрузка на API сервер не влияла на базу данных. Для кластера из 3 мастеров текущая схема оптимальна.

### 5. Как осуществлять резервное копирование (Backup)?

Действительно, в современных образах etcd (distroless) часто нет даже оболочки `sh`, поэтому `docker exec` или `kubectl exec` не помогут запустить команду бэкапа внутри.

**Правильный подход:** Запускать утилиту `etcdctl` **на хосте (самой мастер-ноде)**, подключаясь к etcd по сети (localhost).

**Шаги:**

1.  **Установите etcdctl на мастер-ноду.**
    Вам нужно скачать бинарник той же версии (или близкой), что и в контейнере.
    Посмотрите версию: `kubectl get pod -n kube-system -l component=etcd -o yaml | grep image`
    Скачайте бинарник с GitHub releases etcd и положите в `/usr/local/bin/etcdctl`.

2.  **Найдите сертификаты.**
    Обычно они лежат тут: `/etc/kubernetes/pki/etcd/`.
    Вам нужны:
    *   CA cert: `ca.crt`
    *   Server cert: `server.crt` (или `healthcheck-client.crt` или `peer.crt` — обычно используют `server.crt` или спец. клиентский сертификат).
    *   Key: `server.key`

3.  **Команда для бэкапа (Snapshot save).**
    Запустите прямо в консоли сервера:

    ```bash
    ETCDCTL_API=3 etcdctl \
      --endpoints=https://127.0.0.1:2379 \
      --cacert=/etc/kubernetes/pki/etcd/ca.crt \
      --cert=/etc/kubernetes/pki/etcd/server.crt \
      --key=/etc/kubernetes/pki/etcd/server.key \
      snapshot save /tmp/etcd-backup-$(date +%Y-%m-%d).db
    ```

    *Если команда сработала успешно, вы увидите "Snapshot saved at ...".*

4.  **Автоматизация:**
    Добавьте этот скрипт в `cron` на одной из мастер-нод (или на всех, если хотите надежности, но тогда нужно чистить старые). Не забывайте переносить файлы бэкапа на внешнее хранилище (S3, FTP, другой сервер).

**Важное замечание про восстановление:**
Восстановление (restore) — более сложная процедура. Она требует остановки всех инстансов API-серверов и etcd, удаления старых данных из `/var/lib/etcd` и запуска команды `etcdctl snapshot restore` с определенными флагами. Рекомендую протестировать восстановление на тестовом стенде.
