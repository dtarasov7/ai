Вот список **ключевых метрик для мониторинга кластера Kubernetes и балансировщиков через Zabbix**, которые позволят дежурной смене оперативно выявлять критические проблемы, не перегружая их излишними алертами.

> ⚠️ Важное ограничение: используется **Zabbix Agent v1**, что означает отсутствие поддержки пользовательских параметров в формате `UserParameter=...`, как в Zabbix Agent 2. Поэтому большинство проверок будет выполняться **через активные проверки на сервере Zabbix** (например, через HTTP-запросы или скрипты, запускаемые на сервере Zabbix).

---

## 📌 Общие принципы:
- **Исключены инфраструктурные метрики хостов** (CPU, RAM, диск).
- Проверки должны быть **минималистичными и высокозначимыми**.
- Алерты должны **минимизировать ложные срабатывания** (используем задержки и пороговые значения).
- Приоритет — **доступность сервисов, стабильность управления кластером и работа Ingress**.

---

## ✅ Метрики для мониторинга

### 1. **Доступность kube-apiserver через внешний LB**
- **Описание**: Проверяет, доступен ли API Kubernetes по внешнему адресу (через балансировщик).
- **Как получать**: Активный HTTP-запрос от Zabbix Server к `https://<lb-ip>/version` с авторизацией или без (в зависимости от конфигурации).
- **Порог**: 
  - Ответ со статусом `200 OK`.
  - Таймаут: 5 секунд.
  - Алерт при недоступности более **3 минут**.
- **Рекомендации**:
  - Использовать TLS-проверку сертификата.
  - Запрашивать `/version` или `/livez`.

---

### 2. **Доступность master nodes**
- **Описание**: Проверяет, доступны ли master-ноды напрямую (не через LB), чтобы обнаружить проблему с самими мастерами.
- **Как получать**: Активный HTTP-запрос от Zabbix Server к каждому master node (`https://<master-ip>:6443/version`) с проверкой сертификата.
- **Порог**:
  - Статус 200 OK.
  - Алерт, если **более одного master недоступен**.
  - Длительность проверки: 3 попытки с интервалом 1 мин.
- **Примечание**: Если LB работает, но один master упал — это предупреждение, но не критика.

---

### 3. **Количество нод в Ready состоянии**
- **Описание**: Проверяет, все ли worker-ноды находятся в состоянии Ready.
- **Как получать**:
  - Через API Kubernetes: GET `/api/v1/nodes`.
  - Фильтруем по `.items.status.conditions[?type==Ready].status == "True"`.
- **Как реализовать**:
  - Выполнять запрос от Zabbix Server к API с токеном или kubeconfig.
  - Парсить JSON и считать количество Ready-нод.
- **Порог**:
  - Алерт, если число Ready-нод < 80% от общего числа.
  - Учитывать минимальное количество нод, допустимое для работы кластера.

---

### 4. **Наличие NotReady нод**
- **Описание**: Проверяет, есть ли ноды в состоянии NotReady.
- **Как получать**:
  - То же, что и выше: запрос к `/api/v1/nodes`, фильтр по условиям.
- **Порог**:
  - Алерт, если есть хотя бы одна NotReady-нода.
  - Исключения: если известно, что нода в обслуживании (можно игнорировать по label).
  - Задержка перед алертом: 5 минут (чтобы избежать ложных срабатываний при перезагрузке).

---

### 5. **Наличие pod'ов в состоянии CrashLoopBackOff**
- **Описание**: Позволяет выявить падающие контейнеры в системных компонентах.
- **Как получать**:
  - Запрос к API: `/api/v1/pods?fieldSelector=status.phase!=Running`.
  - Фильтровать по namespace (например, `kube-system`, `istio-system`).
- **Порог**:
  - Алерт, если есть хотя бы один pod в состоянии `CrashLoopBackOff`.
  - Можно исключить тестовые поды.
- **Примечание**: Не стоит отслеживать все namespace, только системные.

---

### 6. **Наличие pod'ов в состоянии Pending**
- **Описание**: Позволяет выявить проблемы с планировщиком или ресурсами.
- **Как получать**:
  - Запрос к `/api/v1/pods?fieldSelector=status.phase=Pending`.
- **Порог**:
  - Алерт, если количество таких pod’ов > 3 в течение 5 минут.
  - Исключить известные pending-поды (например, Job, CronJob).

---

### 7. **Доступность Ingress контроллеров (Istio)**
- **Описание**: Проверяет, принимают ли ingress-узлы трафик.
- **Как получать**:
  - Активный HTTP-запрос от Zabbix Server к одному из ingress-нод на порту 80/443 с валидным Host-заголовком.
- **Порог**:
  - Статус ответа 200 или 404 (если нет соответствующего VirtualService).
  - Алерт, если оба ingress-сервера недоступны.
  - Таймаут: 5 секунд.
  - Алерт после 3 неудачных попыток.

---

### 8. **Здоровье Istio control plane**
- **Описание**: Проверяет доступность основных компонентов Istio (pilot, citadel, mixer и т.д.)
- **Как получать**:
  - Проверка наличия Pod'ов в `istio-system` в состоянии Running.
  - Проверка health endpoints (если доступны): `/healthz` у каждого компонента.
- **Порог**:
  - Алерт, если какой-либо из компонентов Istio не работает более 5 минут.
  - Можно использовать `/healthz` endpoint или состояние pod'ов.

---

### 9. **Доступность etcd через API сервер**
- **Описание**: Проверяет работоспособность etcd, который критичен для кластера.
- **Как получать**:
  - Через API Kubernetes: попытка создания временного объекта (например ConfigMap).
- **Порог**:
  - Алерт, если создание объекта завершается ошибкой (например, timeout или InternalServerError).
  - Интервал проверки: 1 раз в 5 минут.

---

### 10. **Доступность nginx на балансировщиках**
- **Описание**: Проверяет, что nginx слушает порт и отвечает на запросы.
- **Как получать**:
  - Активный HTTP-запрос от Zabbix Server к каждому балансировщику.
- **Порог**:
  - Статус 200 или 400 (если хост не найден).
  - Алерт, если оба балансировщика недоступны.
  - Таймаут: 3 секунды.

---

### 11. **VIP keepalived доступен**
- **Описание**: Проверяет, что VIP балансировщика доступен (например, пингуется или отвечает на TCP).
- **Как получать**:
  - TCP-проверка или ICMP-пинг от Zabbix Server до VIP.
- **Порог**:
  - Алерт, если VIP не отвечает более 1 минуты.
  - Рекомендуется TCP-проверка на порт 443 или 80.

---

## 🧪 Возможные дополнительные проверки (по желанию):
- Количество неподтвержденных alert'ов в Alertmanager (если он установлен).
- Проверка состояния CoreDNS (работает ли DNS внутри кластера).
- Проверка состояния kube-proxy и его таблиц маршрутов.

---

## 🔁 Как реализовать проверки в Zabbix?

| Тип проверки | Реализация |
|-------------|------------|
| **HTTP(S)-запросы** | Использовать Web Scenario или Simple Checks в Zabbix. |
| **API-запросы к k8s** | Выполнять через Zabbix Server с помощью curl/wget + парсинг JSON (можно через регулярные выражения). |
| **TCP-проверки** | Использовать Zabbix agent (если возможно), или TCP ping от сервера Zabbix. |
| **Скрипты** | Написать shell-скрипты, которые делают запросы и выводят результат. Выполнять их через Zabbix Server (активные проверки). |

---

## 🧠 Рекомендации по снижению шума:

- **Увеличьте время задержки перед алертом** (например, 3–5 минут).
- **Добавьте зависимости между триггерами** (например, если LB недоступен, не показывать ошибки по отдельным нодам).
- **Используйте корреляцию событий** в Zabbix для группировки алертов.
- **Добавьте режим обслуживания** для плановых работ.

---

## 📦 Пример скрипта для проверки количества Ready нод:

```bash
#!/bin/bash
# Получаем токен сервисного аккаунта или используем kubeconfig
TOKEN=$(cat /etc/kubernetes/token)
K8S_API="https://<lb-ip>:6443"

curl -k -H "Authorization: Bearer $TOKEN" "$K8S_API/api/v1/nodes" | jq '.items[] | select(.status.conditions[-1].type == "Ready") | .metadata.name' | wc -l
```

> Результат можно отправлять в Zabbix через `system.run` (если есть Zabbix Agent 2), или выполнять на сервере Zabbix как активную проверку.

---

Если потребуется — могу предоставить готовые шаблоны для Zabbix и примеры триггеров.
