## Мониторинг Kubernetes кластера в Zabbix 6.4

Этот список метрик и проверок предназначен для мониторинга Kubernetes кластера с помощью Zabbix 6.4 и Zabbix Agent 1, фокусируясь на критичных для дежурной смены аспектах и минимизируя ложные срабатывания.

**I. Балансировщики (LB)**

1. **Доступность LB:**
    * **Метрика:** HTTP/HTTPS проверка доступности виртуального IP LB.
    * **Получение:** Zabbix server (web scenario).
    * **Пороги:**  Ошибка ответа (codes != 2xx) -  CRITICAL.
    * **Обоснование:** Первичная проверка. Если LB недоступен, весь кластер недоступен.

2. **Доступность backend nginx на LB:**
    * **Метрика:** TCP проверка порта nginx на каждом сервере LB.
    * **Получение:** Zabbix server.
    * **Пороги:** Недоступен порт - WARNING.
    * **Обоснование:** Позволяет определить, какой из серверов LB неисправен.

**II. Kubernetes API**

3. **Доступность Kubernetes API через LB:**
    * **Метрика:** HTTP GET запрос к `/healthz` endpoint Kubernetes API через LB.
    * **Получение:** Zabbix server (web scenario).
    * **Пороги:** Ошибка ответа (codes != 2xx) - CRITICAL.
    * **Обоснование:**  Критичная проверка.  Если API недоступен, управление кластером невозможно.

**III. Master Nodes & etcd**

4. **Количество работающих master nodes:**
    * **Метрика:** `kubectl get nodes -l node-role.kubernetes.io/master=true -o jsonpath='{.items[*].status.conditions[?(@.type=="Ready")].status}' | grep -c "True"`
    * **Получение:** Zabbix agent (скрипт).
    * **Пороги:** Меньше 3 - WARNING, Меньше 2 - CRITICAL.
    * **Обоснование:** Контроль работоспособности master nodes.

5. **Статус etcd:**
    * **Метрика:**  `kubectl get pods -n kube-system -l component=etcd -o jsonpath='{.items[*].status.phase}' | grep -c Running` (предполагается стандартное развертывание etcd)
    * **Получение:** Zabbix agent (скрипт).
    * **Пороги:** Меньше 3 - WARNING, Меньше 2 (или 1, в зависимости от конфигурации etcd) - CRITICAL.
    * **Обоснование:**  Критичная проверка. etcd хранит состояние кластера.

**IV. Worker Nodes**

6. **Количество работающих worker nodes:**
    * **Метрика:** `kubectl get nodes -l node-role.kubernetes.io/master!=true -o jsonpath='{.items[*].status.conditions[?(@.type=="Ready")].status}' | grep -c "True"`
    * **Получение:** Zabbix agent (скрипт).
    * **Пороги:**  Зависит от количества worker nodes и допустимого уровня деградации.  Например, WARNING при недоступности 20%, CRITICAL при 50%.
    * **Обоснование:**  Отслеживание доступности worker nodes.

**V. Сетевые проблемы**

7. **Проблемы сетевой связанности между подами:**
    * **Метрика:**  Можно использовать демонизированный pod, который периодически пингует другие поды в разных namespace и на разных узлах. Результат пинга записывается в файл, который читает Zabbix агент.
    * **Получение:** Zabbix agent.
    * **Пороги:**  Потеря пакетов выше определенного порога (например, 10%) - WARNING, полная недоступность - CRITICAL.
    * **Обоснование:**  Выявление проблем с сетевой связанностью внутри кластера.


**VI. Сертификаты**

8. **Срок действия сертификатов:**
    * **Метрика:**  `openssl x509 -in /path/to/certificate.crt -noout -dates | grep notAfter | cut -d= -f2 | xargs -I {} date -d {} +%s`
    * **Получение:**  Zabbix agent (скрипт).
    * **Пороги:** WARNING за 30 дней до истечения, CRITICAL за 7 дней.
    * **Обоснование:**  Предотвращение проблем, связанных с истечением срока действия сертификатов.

**VII. Внешние сервисы**

9. **Доступность DNS, LDAP, репозитория контейнеров:**
    * **Метрика:**  DNS: `nslookup <dns_server>`, LDAP: `ldapsearch -x -H ldap://<ldap_server> -b "" -s base`, Репозиторий: `curl -I <repository_url>`
    * **Получение:** Zabbix agent (скрипт).
    * **Пороги:** Ошибка ответа - CRITICAL.
    * **Обоснование:**  Контроль доступности критически важных внешних сервисов.


**VIII. OOM Killer**

10. **Sрабатывание OOM Killer:**
    * **Метрика:**  `journalctl -k | grep -i "oom killer"` или анализ логов kubelet.
    * **Получение:** Zabbix agent (скрипт + log monitoring).
    * **Пороги:** Любое срабатывание - CRITICAL.
    * **Обоснование:**  OOM killer сигнализирует о серьезных проблемах с нехваткой памяти.

**IX. Дополнительные проверки**

11. **Доступность Ingress контроллера:**
    * **Метрика:** HTTP/HTTPS проверка доступности ingress контроллера через LB.
    * **Получение:** Zabbix server (web scenario).
    * **Пороги:** Ошибка ответа (codes != 2xx) - CRITICAL.
    * **Обоснование:** Проверка доступности ingress контроллера, так как он является точкой входа для внешних запросов к приложениям.


**Примеры шаблонов Zabbix (YAML - экспорт из веб-интерфейса Zabbix)**

Шаблоны для Zabbix в формате YAML сложно предоставить в полном объеме в текстовом формате, так как они содержат много деталей, связанных с настройками элементов данных, триггеров, графиков и т.д.  Лучше создавать шаблоны непосредственно через веб-интерфейс Zabbix.

**Ключевые моменты при создании шаблонов:**

* **Шаблон для LB:**  Содержит проверки доступности виртуального IP и backend nginx.  Применяется к узлам LB.
* **Шаблон для Kubernetes:**  Содержит проверки Kubernetes API, master/worker nodes, etcd, сертификатов, внешних сервисов, OOM killer.  Применяется к одному из master nodes (на котором установлен Zabbix agent и kubectl).  Важно обеспечить корректную работу `kubectl` на этом узле (настройка kubeconfig).
* **Шаблон для Ingress:** Содержит проверки доступности ingress контроллера. Применяется к ingress узлам.


**Скрипты для Zabbix Agent:**

Скрипты должны быть размещены в каталоге, указанном в конфигурации Zabbix агента (`UserParameter`).

**Пример конфигурации Zabbix агента (zabbix_agentd.conf):**

```
UserParameter=kubernetes.master.count,kubectl get nodes -l node-role.kubernetes.io/master=true -o jsonpath='{.items[*].status.conditions[?(@.type=="Ready")].status}' | grep -c "True"
# ... другие UserParameter ...
```

**Важные замечания:**

* Zabbix agent 1 имеет ограниченные возможности.  Для более сложного мониторинга рассмотрите возможность использования Zabbix agent 2 или интеграции с Prometheus.
*  Необходимо настроить права доступа для пользователя, от имени которого запускается Zabbix agent, для выполнения `kubectl` команд.
*  Для мониторинга сетевой связанности между подами необходимо создать специальный pod и настроить его для постоянной работы.
*  Важно тщательно настроить пороги для минимизации ложных срабатываний.  Рекомендуется начать с более высоких порогов и постепенно их снижать по мере накопления статистики.


Этот список предоставляет основу для мониторинга Kubernetes кластера с помощью Zabbix.  Его можно дополнить и модифицировать в зависимости от специфики вашей инфраструктуры и требований.
