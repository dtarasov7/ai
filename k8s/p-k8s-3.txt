Развернут кластер k8s:
- три master nodes
- два ingress nodes
- несколько worker nodes
На кластере развернут istio.
ingress контролер - nginx.
Запросы в кластер поступают через внешний балансировщик (lb)
lb - это два сервера с keepalived . На каждом сервере развернут nginx, который в зависимости от поля host в запросе 
отправляет запрос либо на один из master, либо на один из ingress.
В кластере настроен внутрений мониторинг всех компонент на основе promethus и grafana.

Однако есть внешняя служба мониторинга (дежурная смена), которая использует zabbix и не имеет доступа к 
promethus и grafana в кластере. На каждом хосте установлен zabbix agent version 1 (версия агента - это важно).

Необходимо настроить в zabbix мониторинг основных параметров развернутого кластера, чтобы дежурная смена могла оперативно поянть, 
что с кластером ( или балансировщиками) имеются проблемы и проэскалировать на поддержку кластера

Составь список метрик (проверок), которые имеет смысл настроить в zabbix, чтобы с одной стороны не перегружать 
дежурную сменую излишними алертами, а с другой стороны не пропустить важные события.

Исключи инфраструктурные метрики, то есть метрики хостов ( процессор, RAM, диски и т.д.)

Для каждой метрики укажи как ее эффективней получать - через запрос от сервера glagger к API k8s 
или через zabbix agent (скрипты)

Для каждой метрики укажи рекумендуемые пороги , чтобы минимизировать ложные срабатывания.

Пример таких проверок (метрик):
- недоступность kube api через lb
- проблемы сетевой связанности между узлами или между подами разных узлов
- отказ одного master
- отказ одной из нод кластера etcd
- истекает срок сертификатов
- недоступность корпоративных DNS серверов
- недоступность корпоративных LDAP серверов
- недоступность корпоративного репозитория контейнеров
- срабатывание OOM killer



