Ниже — практичная стратегия PKI именно для Deckhouse в изолированном периметре, где авто‑выпуск сертификатов из корпоративного УЦ по API недоступен. Фокус: как строить контуры доверия, чем и где подписывать, как обновлять без простоя и с минимальным ручным трудом.

Идея в двух словах
- Разделите контур на два мира:
  - Внутренний (Kubernetes/etcd/webhook/mTLS между сервисами) — автономная PKI кластера, короткие сроки, полная автоматизация.
  - Внешний (Ingress/пользовательские веб‑интерфейсы/API, к которым ходят люди/клиенты) — цепочка корпоративного УЦ.
- Так как API УЦ недоступен, добиваемся автоматизации двумя способами: либо единоразово получаем “подчинённый” суб‑CA от корп. УЦ и используем его внутри кластера, либо, если это запрещено, минимизируем количество “ручных” сертификатов (wildcard и/или TLS‑offload на периметре) и автоматизируем мониторинг/релизы.

1) Что где подписываем (Deckhouse)
- Внутри кластера:
  - Kubernetes control‑plane: kubernetes‑ca, front‑proxy‑ca, etcd‑ca, ключ(и) подписи service account токенов. Эти цепочки остаются внутренними и не требуют корпоративного УЦ.
  - mTLS между приложениями: свой внутрикластерный CA (через cert‑manager или SPIFFE/SPIRE), не смешивать с корп. УЦ.
- На границах:
  - Ingress‑контроллер(ы) (ingress‑nginx/istio‑ingress/gateway): сертификаты, цепляющиеся к корпоративному корню, чтобы браузеры/хосты в периметре им доверяли.
  - При необходимости внешнего доступа к kube‑api: либо TLS‑offload корпоративным сертификатом на внешнем балансировщике/прокси и ре‑шифрование внутрь, либо распространение kubernetes‑ca на админские рабочие станции.

2) Три сценария интеграции с корпоративным УЦ без API
- A) Лучший вариант: субординация (one‑time)
  - Запросите у корпоративного УЦ выпуск подчинённого “apps‑subCA” (Intermediate) для доменов приложений (например, *.prod.apps.corp, *.int.corp).
  - Приватный ключ храните вне кластера (Vault/HSM) и синхронизируйте в кластер только через защищённый Secret (SealedSecret/KMS‑провайдер, строгий RBAC/PSA).
  - В Deckhouse включите модуль cert‑manager и создайте ClusterIssuer типа CA, указывающий на секрет с ключом subCA. Все листовые для Ingress и сервисов — автоматом, с renewBefore и алертами.
  - Раз в 2–3 года перевыпускаете subCA тем же офлайн‑процессом (см. “двухфазная ротация CA” ниже).
- B) Субординация запрещена: “периметр + wildcard”
  - Выпускайте 1–3 wildcard‑сертификата у корп. УЦ (например, *.prod.apps.corp, *.stg.apps.corp), ключи держите как критичные секреты. Это резко сокращает количество ручных операций.
  - Подключайте их на ingress‑контроллерах как TLS‑Secrets; ротация — заменой Secret с автоматическим reload у ingress‑контроллера.
  - Для редких “штучных” доменов — ручной цикл CSR→подпись вне кластера→обновление Secret.
- C) TLS‑offload перед API и/или платформенными UI
  - Поставьте периметральный LB/прокси с корпоративным сертификатом; внутрь — mTLS к внутренним сервисам на кластерном CA. Так нужно меньше “корпор. сертов”.

3) Сроки и криптопрофили
- Алгоритмы: ECDSA P‑256 (предпочтительно) или RSA‑3072.
- Сроки:
  - Корп. подчинённый apps‑subCA: 2–3 года.
  - Внутренние CAs (kubernetes‑ca/front‑proxy‑ca/etcd‑ca): 1–2 года.
  - Листовые для ingress/внешних UI: 90–365 дней (подбирайте под операционный процесс; при ручном выпуске обычно 180–365, при subCA — 90–120).
  - Kubelet/внутрикластерные листовые: 30–90 дней.
- В изоляции не полагайтесь на OCSP/CRL: компенсируйте короткими сроками и мониторингом.

4) Первичное создание и загрузка (Deckhouse)
- Внутренний контур:
  - Дайте Deckhouse/Kubernetes управлять внутренними сертификатами (kubelet rotation через CSR API, короткие TTL для листовых). Если кластер развёрнут через kubeadm (типично для Deckhouse), держите регламент на “kubeadm certs renew …” для control‑plane и поочерёдный рестарт kubelet на мастерах при приближении истечения.
- Внешний контур:
  - Сценарий A (subCA):
    1) Сгенерируйте ключ subCA и CSR на офлайн‑станции.
    2) Корп. УЦ подпишет как Intermediate.
    3) Загрузите ключ+cert цепочку в Secret (Namespace cert‑manager или d8‑system, как принято у вас).
    4) Создайте ClusterIssuer типа CA, указывающий на Secret.
    5) Для каждого hostname — объект Certificate; cert‑manager сам создаст Secret и продлит его.
  - Сценарий B (wildcard/ручные):
    1) Выпустите *.apps.corp у УЦ; импортируйте ключ+цепочку в Secret, используйте на ingress.
    2) Для штучных доменов: генерируйте ключ/CSR в кластере (или вне), отправляйте в УЦ, полученный cert+chain кладите в Secret.

Пример (субCA + cert‑manager)
- Secret c subCA:
  apiVersion: v1
  kind: Secret
  metadata:
    name: apps-subca
    namespace: cert-manager
  type: kubernetes.io/tls
  data:
    tls.crt: <base64(subCA certificate + chain)>
    tls.key: <base64(private key)>
- ClusterIssuer:
  apiVersion: cert-manager.io/v1
  kind: ClusterIssuer
  metadata:
    name: apps-subca
  spec:
    ca:
      secretName: apps-subca
- Сертификат для ingress:
  apiVersion: cert-manager.io/v1
  kind: Certificate
  metadata:
    name: ui-prod-cert
    namespace: prod
  spec:
    secretName: ui-prod-tls
    commonName: ui.prod.apps.corp
    dnsNames:
      - ui.prod.apps.corp
    issuerRef:
      name: apps-subca
      kind: ClusterIssuer
    renewBefore: 720h   # 30 дней

5) Ротация: листовые, CA и ключи SA
- Листовые (ingress/UI):
  - cert‑manager: сам перевыпустит и “горячо” обновит Secret → ingress‑контроллер перезагрузит конфиг. Проверьте, что используется полная цепочка (full chain), чтобы клиенты сразу доверяли.
  - Ручные/wildcard: положите новый Secret с тем же именем — ingress сам подхватит; сделайте rollout restart деплойментов, если серт монтируется в контейнер.
- Двухфазная смена CA (subCA/внутренние CAs):
  - Фаза 1 — расширяем доверие: распространяем bundle (старый+новый CA) в проверяющие компоненты (ingress, прокси, клиенты), настраиваем issuer выдавать от НОВОГО CA.
  - Фаза 2 — перевыпускаем листовые по очереди (неймспейсы/домены).
  - Фаза 3 — через максимальный TTL листовых удаляем старый CA из bundle.
- ServiceAccount signing keys:
  - Одновременно указывайте несколько ключей проверки; новый ключ — для подписи, старые — только для verify до истечения максимального TTL токенов, затем удаляйте.

6) Доступ к kube‑api и внешним клиентам
- Для людей/CI лучше OIDC (Deckhouse модуль user‑authn/Dex) вместо клиентских X.509.
- Если нужен корпоративный TLS к kube‑api:
  - Предпочтительно TLS‑offload корпоративным cert на внешнем LB/прокси → mTLS внутрь.
  - Либо распространите kubernetes‑ca на админские рабочие места (через GPO/Ansible/образ ОС).

7) Распространение доверия
- Корпоративные корни/промежуточные:
  - Узлы кластера (хост‑ОС) — добавить в системные trust‑stores, чтобы контейнеры доверяли исходящим соединениям к внутренним ресурсам.
  - Образы/Java‑кастомеры — в т.ч. импорт в JKS cacerts.
- Внутренние класт. CAs — раздать только тем, кому нужен прямой доступ к API/вебхукам (обычно админы/бастион).

8) Мониторинг и оповещения
- cert‑manager метрики: следите за сроками сертификатов, alert при <30 дней.
- Для “ручных” TLS‑секретов: CronJob/экспортер, который раз в N часов обходит Secrets типа kubernetes.io/tls, парсит NotAfter и публикует метрику в Prometheus; алерт “<30 дней”.
- Технический контроль: регулярно проверяйте SAN/цепочки, чтобы ingress всегда отдавал полный chain.

9) Безопасность секретов и бэкапы
- Включите шифрование Secret’ов в etcd (EncryptionConfiguration).
- Храните ключи subCA/wildcard как минимально доступные Secrets (PSA=restricted, RBAC только на чтение для контроллера, запрет на exec/ephemeral‑контейнеры).
- Регулярные офлайн‑бэкапы etcd и Secrets с ключами; проверка восстановления.

10) Плейбуки (сжатые)
- Ручная ротация wildcard на ingress‑nginx:
  1) Получить новый cert+chain у УЦ.
  2) kubectl -n ingress-nginx create secret tls wildcard-prod --cert=fullchain.pem --key=key.pem -o yaml --dry-run=client | kubectl apply -f -
  3) Убедиться, что контроллер перечитал конфиг (в логах/метриках); проверить сайт.
- SubCA ротация (без простоя):
  1) Выпустить новый subCA у УЦ, собрать bundle “old+new”.
  2) Обновить ClusterIssuer на новый subCA (или создать параллельный и перевыпускать Certificate поэтапно).
  3) Через максимальный TTL листовых удалить старый CA из bundle на клиентах.
- Авария: протух kube‑api cert и нет доступа:
  - На master по SSH: если кластер на kubeadm — kubeadm certs renew apiserver apiserver-kubelet-client front-proxy-client && systemctl restart kubelet; проверить здоровье. Иначе — ваш регламент Deckhouse/Ansible на перевыпуск статических Pod‑сертов.

Рекомендуемые сроки/ритм
- Листовые ingress: 90–180 дней (при subCA — 90–120).
- Внутрикластерные листовые: 30–90 дней.
- Внутренние CAs: 1–2 года.
- SubCA: 2–3 года.
- Алерты: T‑60/T‑30/T‑7 дней.

Что уточнить, чтобы дать готовые манифесты/скрипты под вас
- Разрешает ли политика получить подчинённый CA для приложений?
- Какой ingress используете (ingress‑nginx/istio‑gateway) и как организован периметральный LB?
- Нужен ли корпоративный TLS к kube‑api или достаточно распространить kubernetes‑ca?
- Кластер развёрнут через kubeadm (стандартный путь Deckhouse) или кастомно?

Отвечу точными YAML/скриптами для выбранного сценария (subCA или wildcard), включая RBAC/PSA, Prometheus‑алерты на истечения и пошаговую ротацию без простоя.
