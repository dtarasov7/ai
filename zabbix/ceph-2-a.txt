Проверяю запрос пользователя
Подождите, в вопросе пользователя не упоминается вложение. Давайте перепроверим.
Пользователь просит рассмотреть вариант 1 подробнее, исключая zabbix_sender. Нужно сосредоточиться на этом.
Я думаю, вариант 1 подразумевает использование UserParameters в Zabbix Agent для мониторинга Ceph. Давайте уточним детали.
Пользователь описал кластер Ceph: 5 серверов mon (с mgr), 4 RadosGW на порту 8443, 6 OSD, haproxy на 443 и keepalived для VIP.
Ищу информацию
Обычно для мониторинга Ceph устанавливают Zabbix Agent на серверах с компонентами Ceph.
Для общего статуса кластера достаточно агента на одном сервере mon. Но для доступности сервисов лучше иметь агенты на каждом сервере.
Я сейчас думаю, как лучше организовать мониторинг. Давайте рассмотрим, где разместить агенты.
Для общего статуса кластера можно выбрать один сервер mon. А для проверки сервисов, вроде radosgw, нужно агенты на каждом сервере.
Лучше создать хост в Zabbix для каждого физического сервера. Так мы сможем мониторить локальные сервисы.
На одном сервере mon настроим дополнительные UserParameters для общего статуса кластера. Это упростит сбор данных.
Планирую скрипты
Для серверов mon нужно проверить, работают ли сервисы mon и mgr.
На одном сервере mon соберем общий статус кластера. Это важно для мониторинга.
Для RadosGW серверов проверим, запущен ли radosgw и отвечает ли на порт 8443. Также проверим haproxy, он должен быть активным.
На OSD серверах нужно убедиться, что все OSD сервисы работают без ошибок. Это обеспечит надежность кластера.
Я сейчас думаю, как создать скрипт для проверки сервисов. Давайте начнем с mon серверов.
Для скрипта на серверах mon можно использовать systemctl для проверки статуса сервисов mon и mgr. Это просто и надежно.
На одном сервере mon создадим скрипт для получения статуса здоровья кластера, например, с помощью команды ceph -s. Это поможет мониторить общее состояние.
Для проверки radosgw на серверах RadosGW используем тот же скрипт, но добавим проверку ответа на порт 8443. Это важно для HTTPS запросов.
Создаю скрипты
Создадим скрипт для проверки сервисов, например, /usr/local/bin/check_service.sh. Он будет использовать systemctl для статуса.
Для radosgw добавим скрипт, который проверит ответ на порт 8443 с помощью curl. Это обеспечит проверку HTTPS.
Скрипт для radosgw проверит доступность HTTPS на localhost:8443. Он вернет 1, если статус 200 или 403, иначе 0.
Для OSD серверов создадим скрипт, который проверит все сервисы ceph-osd. Это поможет мониторить каждый OSD.
Я сейчас думаю, как улучшить скрипт для OSD. Давайте создадим скрипт, который подсчитает активные OSD сервисы.
Улучшаю скрипты OSD
Создадим скрипт /usr/local/bin/check_osd_services.sh для подсчета активных OSD сервисов. Он проверит статус каждого с помощью systemctl.
Этот скрипт поможет мониторить, сколько OSD активно на сервере. Это важно для оценки здоровья кластера.
Для RadosGW серверов настроим UserParameter для проверки статуса radosgw. Используем check_systemd_service.sh с нужным именем сервиса.
Настройка Zabbix включает создание хостов для каждого сервера. Для mon серверов добавим элементы для статуса mon и mgr.
Настраиваю Zabbix
Для сервисов mon, mgr, radosgw, haproxy настроим триггеры, если значение равно 0 (не работает).
Для ceph.radosgw.https триггер сработает, если значение 0 (не отвечает). Для ceph.cluster.health триггер, если значение больше 0 (не HEALTH_OK).
Я сейчас думаю, как завершить настройку. Давайте добавим триггеры для OSD активного счета.
Для ceph.osd.active_count настроим триггер, если значение меньше ожидаемого числа OSD на сервере. Это поможет отслеживать проблемы.
Настройка завершена. Давайте подведем итоги для пользователя.
Я сейчас готовлю скрипты и настройки для мониторинга Ceph кластера. Давайте создадим артефакт с этими скриптами.
Готовлю артефакт
Создаю артефакт с скриптами для мониторинга Ceph. Это поможет пользователю настроить Zabbix.
