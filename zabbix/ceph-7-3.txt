



### Ответ на запрос

**Ключевые моменты:**
- Для проверки сетевой связности между каждым OSD сервером (`osd1`–`osd6`) мы модифицируем скрипт `osd_connectivity.sh`, чтобы выполнять 5 пингов для каждого сервера и допускать до одной потери пакета, считая сервер доступным, если успешно получено хотя бы 4 ответа из 5.
- Триггер будет срабатывать, если связность отсутствует дольше заданных временных порогов:
  - **Warning**: Нет связности дольше 5 минут, но меньше 15 минут.
  - **Error**: Нет связности дольше 15 минут, но меньше 30 минут.
  - **Critical**: Нет связности дольше 30 минут.
- В Zabbix невозможно создать один триггер с разными уровнями серьезности (`Warning`, `Error`, `Critical`) в зависимости от времени, поэтому мы создадим три отдельных триггера с соответствующими условиями.
- Связность считается отсутствующей, если `net.osd.connectivity > 0` (хотя бы один сервер недоступен по пингу).
- Решение интегрируется в существующий XML-шаблон Zabbix, обновляя `Ceph OSD Template` с новым элементом данных и тремя триггерами, сохраняя все предыдущие метрики и триггеры для mon, RadosGW и OSD.

**Обзор решения**  
- **Скрипт**: Модифицируем `osd_connectivity.sh` на каждом OSD сервере, чтобы выполнять 5 пингов с таймаутом 1 секунда для каждого из 5 других OSD серверов. Сервер считается недоступным, если потеряно более 1 пакета (менее 4 успешных ответов).
- **UserParameter**: Остается `net.osd.connectivity`, возвращающий количество недоступных серверов (0–5).
- **Элемент данных**: `net.osd.connectivity` в `Ceph OSD Template` собирает данные каждые 60 секунд.
- **Триггеры**:
  - **Warning**: `{HOST.HOST:net.osd.connectivity.min(5m)}>0` — срабатывает, если связность отсутствует хотя бы 5 минут.
  - **Error**: `{HOST.HOST:net.osd.connectivity.min(15m)}>0 and {HOST.HOST:net.osd.connectivity.min(30m)}=0` — срабатывает, если связность отсутствует 15–30 минут.
  - **Critical**: `{HOST.HOST:net.osd.connectivity.min(30m)}>0` — срабатывает, если связность отсутствует более 30 минут.
- XML-шаблон обновляется, чтобы включить новый скрипт, элемент данных и триггеры, сохраняя существующую функциональность.

**Как это работает**  
- На каждом OSD сервере скрипт пингует 5 других серверов, выполняя 5 пингов для каждого. Сервер считается недоступным, если менее 4 пингов успешны.
- Zabbix собирает данные через `net.osd.connectivity`, где значение > 0 указывает на проблемы связности.
- Триггеры используют функцию `min()` для проверки, что `net.osd.connectivity > 0` на протяжении заданного интервала:
  - `min(5m)` проверяет минимальное значение за 5 минут.
  - Условие `min(30m)=0` в триггере `Error` исключает случаи, когда проблема длится более 30 минут, чтобы избежать перекрытия с `Critical`.
- Триггеры применяются ко всем OSD хостам через шаблон, используя `{HOST.HOST}` для универсальности.

---

### Полное решение

#### Введение
Для мониторинга сетевой связности между каждым OSD сервером (`osd1`–`osd6`) в Ceph кластере версии 17.2.7 с использованием Zabbix Agent 1 мы обновим скрипт `osd_connectivity.sh`, чтобы выполнять 5 пингов с допуском одной потери пакета, и добавим три триггера с разными уровнями серьезности в зависимости от длительности отсутствия связности:
- **Warning**: 5–15 минут.
- **Error**: 15–30 минут.
- **Critical**: Более 30 минут.
Решение интегрируется в существующий XML-шаблон, обновляя `Ceph OSD Template`, и сохраняет все метрики и триггеры для mon, RadosGW и OSD.

#### Настройка на OSD серверах
##### Скрипт для проверки связности
Обновите или создайте скрипт на каждом OSD сервере в `/usr/local/bin/osd_monitor`:

**osd_connectivity.sh**:
```bash
#!/bin/bash
# Список всех OSD серверов, исключая текущий хост
current_host=$(hostname)
osd_hosts=("osd1" "osd2" "osd3" "osd4" "osd5" "osd6")
unavailable=0

for host in "${osd_hosts[@]}"; do
  # Пропускаем текущий хост
  [ "$host" == "$current_host" ] && continue
  # Выполняем 5 пингов, таймаут 1 секунда
  ping_result=$(ping -c 5 -W 1 "$host" | grep "received" | awk '{print $4}')
  # Считаем сервер недоступным, если получено менее 4 ответов
  [ "$ping_result" -lt 4 ] && ((unavailable++))
done

echo $unavailable
```

- **Объяснение**:
  - `ping -c 5 -W 1 "$host"`: Выполняет 5 пингов с таймаутом 1 секунда.
  - `grep "received" | awk '{print $4}'`: Извлекает количество полученных пакетов (0–5).
  - `[ "$ping_result" -lt 4 ]`: Считает сервер недоступным, если получено менее 4 ответов (допускается 1 потеря).
  - `unavailable` увеличивается для каждого недоступного сервера.
  - Возвращается общее количество недоступных серверов (0–5).

Сделайте скрипт исполняемым:
```bash
chmod +x /usr/local/bin/osd_monitor/osd_connectivity.sh
```

##### Конфигурация Zabbix Agent 1
UserParameter уже существует в `/etc/zabbix/zabbix_agentd.conf` от предыдущего решения:
```ini
UserParameter=net.osd.connectivity,/usr/local/bin/osd_monitor/osd_connectivity.sh
```

Если он отсутствует, добавьте его и перезапустите Zabbix Agent:
```bash
systemctl restart zabbix-agent
```

##### Предположения
- Имена хостов `osd1`–`osd6` разрешены через DNS или `/etc/hosts`.
- Пользователь `zabbix` имеет права на выполнение `ping`. Если требуется `sudo`, настройте `/etc/sudoers`:
  ```bash
  zabbix ALL=(ALL) NOPASSWD: /bin/ping
  ```
  И измените скрипт, добавив `sudo` перед `ping`:
  ```bash
  ping_result=$(sudo ping -c 5 -W 1 "$host" | grep "received" | awk '{print $4}')
  ```
- Альтернатива: Используйте `setcap` для `ping`:
  ```bash
  setcap cap_net_raw+ep /bin/ping
  ```

#### Обновление Zabbix сервера
##### Элемент данных
Элемент данных `net.osd.connectivity` уже присутствует в `Ceph OSD Template`:
- **Название**: `OSD Connectivity Issues`
- **Ключ**: `net.osd.connectivity`
- **Тип**: Zabbix agent (0)
- **Тип значения**: Numeric (unsigned) (3)
- **Интервал**: 60 секунд
- **Описание**: Количество OSD серверов, недоступных через пинг (0–5)

##### Триггеры
Три новых триггера заменяют предыдущий триггер в `Ceph OSD Template`:
1. **Warning триггер**:
   - **Название**: `OSD Network Connectivity Warning (5-15 minutes)`
   - **Выражение**: `{HOST.HOST:net.osd.connectivity.min(5m)}>0 and {HOST.HOST:net.osd.connectivity.min(15m)}=0`
   - **Приоритет**: `Warning` (2)
   - **Описание**: Срабатывает, если хотя бы один OSD сервер недоступен 5–15 минут.
   - **Объяснение**:
     - `min(5m)>0`: Проблема длится не менее 5 минут.
     - `min(15m)=0`: Исключает случаи, когда проблема длится 15 минут или больше.

2. **Error триггер**:
   - **Название**: `OSD Network Connectivity Error (15-30 minutes)`
   - **Выражение**: `{HOST.HOST:net.osd.connectivity.min(15m)}>0 and {HOST.HOST:net.osd.connectivity.min(30m)}=0`
   - **Приоритет**: `Average` (3)
   - **Описание**: Срабатывает, если хотя бы один OSD сервер недоступен 15–30 минут.
   - **Объяснение**:
     - `min(15m)>0`: Проблема длится не менее 15 минут.
     - `min(30m)=0`: Исключает случаи, когда проблема длится 30 минут или больше.

3. **Critical триггер**:
   - **Название**: `OSD Network Connectivity Critical (30+ minutes)`
   - **Выражение**: `{HOST.HOST:net.osd.connectivity.min(30m)}>0`
   - **Приоритет**: `Critical` (5)
   - **Описание**: Срабатывает, если хотя бы один OSD сервер недоступен более 30 минут.
   - **Объяснение**:
     - `min(30m)>0`: Проблема длится не менее 30 минут.

Использование `{HOST.HOST}` делает триггеры универсальными для всех OSD хостов (`osd1`–`osd6`).

##### XML-шаблон
Обновленный XML-шаблон включает модифицированный `Ceph OSD Template` с элементом данных `net.osd.connectivity` и тремя новыми триггерами. Остальные шаблоны (`Ceph Mon Template`, `Ceph RadosGW Template`) остаются без изменений, но включены для полноты.

```xml
<?xml version="1.0" encoding="UTF-8"?>
<zabbix_export>
    <version>5.0</version>
    <date>2025-05-08T20:00:00Z</date>
    <groups>
        <group>
            <name>Templates</name>
        </group>
    </groups>
    <templates>
        <!-- Шаблон для серверов mon -->
        <template>
            <name>Ceph Mon Template</name>
            <groups>
                <group>
                    <name>Templates</name>
                </group>
            </groups>
            <items>
                <item>
                    <name>Ceph Cluster Health</name>
                    <type>0</type>
                    <key>ceph.health</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>0=HEALTH_OK, 1=HEALTH_WARN, 2=HEALTH_ERR</description>
                </item>
                <item>
                    <name>Ceph Monitors Up</name>
                    <type>0</type>
                    <key>ceph.mon.up</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>0=All monitors up, 1=Some monitors down</description>
                </item>
                <item>
                    <name>Ceph Managers Up</name>
                    <type>0</type>
                    <key>ceph.mgr.up</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>0=Active manager present, 1=No active manager</description>
                </item>
                <item>
                    <name>Ceph OSDs Up</name>
                    <type>0</type>
                    <key>ceph.osd.up</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>0=All OSDs up, 1=Some OSDs down</description>
                </item>
                <item>
                    <name>Ceph RadosGW Up</name>
                    <type>0</type>
                    <key>ceph.radosgw.up</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>0=RadosGW active, 1=RadosGW inactive</description>
                </item>
                <item>
                    <name>Local Ceph Mon Status</name>
                    <type>0</type>
                    <key>ceph.mon.local.status</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>0=Mon service running, 1=Mon service stopped</description>
                </item>
                <item>
                    <name>Local Ceph Mgr Status</name>
                    <type>0</type>
                    <key>ceph.mgr.local.status</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>0=Mgr service running, 1=Mgr service stopped</description>
                </item>
                <item>
                    <name>Ceph Pool Status</name>
                    <type>0</type>
                    <key>ceph.pool.status</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>0=No recovery/degraded/misplaced, 1=Issues detected</description>
                </item>
                <item>
                    <name>Ceph IOPS</name>
                    <type>0</type>
                    <key>ceph.iops</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <units>ops/s</units>
                    <description>Cluster IOPS</description>
                </item>
                <item>
                    <name>Ceph Throughput</name>
                    <type>0</type>
                    <key>ceph.throughput</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <units>bytes/s</units>
                    <description>Cluster throughput</description>
                </item>
                <item>
                    <name>Ceph Latency</name>
                    <type>0</type>
                    <key>ceph.latency</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <units>ms</units>
                    <description>Apply latency in milliseconds</description>
                </item>
                <item>
                    <name>Network Interface Status</name>
                    <type>0</type>
                    <key>net.interface.status</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>1=Interface up, 0=Interface down</description>
                </item>
            </items>
            <triggers>
                <trigger>
                    <name>Ceph Cluster Health Issue on mon1 and mon2</name>
                    <expression>
                        ({ceph-mon1:ceph.health.last(0)}>0 and {ceph-mon2:ceph.health.last(0)}>0) or
                        ({ceph-mon1:ceph.health.nodata(5m)}=1 and {ceph-mon2:ceph.health.last(0)}>0) or
                        ({ceph-mon2:ceph.health.nodata(5m)}=1 and {ceph-mon1:ceph.health.last(0)}>0)
                    </expression>
                    <priority>4</priority>
                    <description>Ceph cluster is not HEALTH_OK on both mon1 and mon2, or one is unreachable and the other reports an issue.</description>
                    <status>0</status>
                </trigger>
            </triggers>
        </template>

        <!-- Шаблон для серверов RadosGW -->
        <template>
            <name>Ceph RadosGW Template</name>
            <groups>
                <group>
                    <name>Templates</name>
                </group>
            </groups>
            <items>
                <item>
                    <name>RadosGW Status</name>
                    <type>0</type>
                    <key>radosgw.status</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>0=RadosGW running, 1=RadosGW stopped</description>
                </item>
                <item>
                    <name>HAProxy Status</name>
                    <type>0</type>
                    <key>haproxy.status</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>0=HAProxy running, 1=HAProxy stopped</description>
                </item>
                <item>
                    <name>Keepalived Status</name>
                    <type>0</type>
                    <key>keepalived.status</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>0=Keepalived running, 1=Keepalived stopped</description>
                </item>
                <item>
                    <name>RadosGW HTTP Check</name>
                    <type>0</type>
                    <key>radosgw.http</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>0=HTTP 200 OK, 1=HTTP error</description>
                </item>
                <item>
                    <name>HAProxy Connections</name>
                    <type>0</type>
                    <key>haproxy.connections</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <units>connections</units>
                    <description>Number of active HAProxy connections</description>
                </item>
                <item>
                    <name>Keepalived VIP Status</name>
                    <type>0</type>
                    <key>keepalived.vip.status</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>1=MASTER, 0=BACKUP</description>
                </item>
                <item>
                    <name>Network Interface Status</name>
                    <type>0</type>
                    <key>net.interface.status</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>1=Interface up, 0=Interface down</description>
                </item>
            </items>
            <triggers>
                <trigger>
                    <name>RadosGW Partial Failure (1-3 servers unavailable)</name>
                    <expression>
                        (
                            ({radosgw1:radosgw.http.last(0)}=1 or {radosgw1:radosgw.http.nodata(5m)}=1) +
                            ({radosgw2:radosgw.http.last(0)}=1 or {radosgw2:radosgw.http.nodata(5m)}=1) +
                            ({radosgw3:radosgw.http.last(0)}=1 or {radosgw3:radosgw.http.nodata(5m)}=1) +
                            ({radosgw4:radosgw.http.last(0)}=1 or {radosgw4:radosgw.http.nodata(5m)}=1)
                        ) >= 1 and
                        (
                            ({radosgw1:radosgw.http.last(0)}=1 or {radosgw1:radosgw.http.nodata(5m)}=1) +
                            ({radosgw2:radosgw.http.last(0)}=1 or {radosgw2:radosgw.http.nodata(5m)}=1) +
                            ({radosgw3:radosgw.http.last(0)}=1 or {radosgw3:radosgw.http.nodata(5m)}=1) +
                            ({radosgw4:radosgw.http.last(0)}=1 or {radosgw4:radosgw.http.nodata(5m)}=1)
                        ) <= 3
                    </expression>
                    <priority>3</priority>
                    <description>1 to 3 RadosGW servers are unavailable (HTTP error or no data).</description>
                    <status>0</status>
                </trigger>
                <trigger>
                    <name>RadosGW Total Failure (All 4 servers unavailable)</name>
                    <expression>
                        (
                            ({radosgw1:radosgw.http.last(0)}=1 or {radosgw1:radosgw.http.nodata(5m)}=1) +
                            ({radosgw2:radosgw.http.last(0)}=1 or {radosgw2:radosgw.http.nodata(5m)}=1) +
                            ({radosgw3:radosgw.http.last(0)}=1 or {radosgw3:radosgw.http.nodata(5m)}=1) +
                            ({radosgw4:radosgw.http.last(0)}=1 or {radosgw4:radosgw.http.nodata(5m)}=1)
                        ) = 4
                    </expression>
                    <priority>5</priority>
                    <description>All 4 RadosGW servers are unavailable (HTTP error or no data).</description>
                    <status>0</status>
                </trigger>
            </triggers>
        </template>

        <!-- Шаблон для серверов OSD -->
        <template>
            <name>Ceph OSD Template</name>
            <groups>
                <group>
                    <name>Templates</name>
                </group>
            </groups>
            <items>
                <item>
                    <name>OSD 0 Status</name>
                    <type>0</type>
                    <key>osd.status.0</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>0=OSD running, 1=OSD stopped</description>
                </item>
                <item>
                    <name>OSD 0 Disk Free</name>
                    <type>0</type>
                    <key>osd.disk.free.0</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <units>bytes</units>
                    <description>Free disk space for OSD 0</description>
                </item>
                <item>
                    <name>Network Interface Status</name>
                    <type>0</type>
                    <key>net.interface.status</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>1=Interface up, 0=Interface down</description>
                </item>
                <item>
                    <name>OSD Connectivity Issues</name>
                    <type>0</type>
                    <key>net.osd.connectivity</key>
                    <delay>60</delay>
                    <history>7</history>
                    <trends>365</trends>
                    <value_type>3</value_type>
                    <description>Number of OSD servers unreachable via ping (0-5)</description>
                </item>
            </items>
            <triggers>
                <trigger>
                    <name>OSD Network Connectivity Warning (5-15 minutes)</name>
                    <expression>{HOST.HOST:net.osd.connectivity.min(5m)}>0 and {HOST.HOST:net.osd.connectivity.min(15m)}=0</expression>
                    <priority>2</priority>
                    <description>At least one OSD server is unreachable via ping for 5-15 minutes.</description>
                    <status>0</status>
                </trigger>
                <trigger>
                    <name>OSD Network Connectivity Error (15-30 minutes)</name>
                    <expression>{HOST.HOST:net.osd.connectivity.min(15m)}>0 and {HOST.HOST:net.osd.connectivity.min(30m)}=0</expression>
                    <priority>3</priority>
                    <description>At least one OSD server is unreachable via ping for 15-30 minutes.</description>
                    <status>0</status>
                </trigger>
                <trigger>
                    <name>OSD Network Connectivity Critical (30+ minutes)</name>
                    <expression>{HOST.HOST:net.osd.connectivity.min(30m)}>0</expression>
                    <priority>5</priority>
                    <description>At least one OSD server is unreachable via ping for more than 30 minutes.</description>
                    <status>0</status>
                </trigger>
            </triggers>
        </template>
    </templates>
</zabbix_export>
```

#### Как использовать
1. **Установка скрипта**:
   - Обновите или создайте `osd_connectivity.sh` на каждом OSD сервере (`osd1`–`osd6`) в `/usr/local/bin/osd_monitor`.
   - Убедитесь, что скрипт исполняемый:
     ```bash
     chmod +x /usr/local/bin/osd_monitor/osd_connectivity.sh
     ```
   - Проверьте выполнение от имени пользователя `zabbix`:
     ```bash
     sudo -u zabbix /usr/local/bin/osd_monitor/osd_connectivity.sh
     ```
2. **Настройка Zabbix Agent**:
   - Убедитесь, что UserParameter `net.osd.connectivity` присутствует в `/etc/zabbix/zabbix_agentd.conf`:
     ```ini
     UserParameter=net.osd.connectivity,/usr/local/bin/osd_monitor/osd_connectivity.sh
     ```
   - Перезапустите Zabbix Agent:
     ```bash
     systemctl restart zabbix-agent
     ```
3. **Импорт шаблона**:
   - Сохраните XML в файл, например, `ceph_templates_with_osd_connectivity.xml`.
   - Импортируйте в Zabbix: **Configuration** > **Templates** > **Import**.
4. **Привязка шаблона**:
   - Убедитесь, что `Ceph OSD Template` привязан к хостам `osd1`–`osd6`.
   - Проверьте, что имена хостов в Zabbix соответствуют `osd1`–`osd6`.
5. **Проверка**:
   - Данные появятся в **Monitoring** > **Latest Data** для ключа `net.osd.connectivity`.
   - Симулируйте сбой сети (например, `ip link set eth0 down` на `osd2`) и проверьте, срабатывают ли триггеры в **Monitoring** > **Triggers** через 5, 15 и 30 минут.

#### Ограничения и соображения
- **DNS/hosts**: Имена хостов `osd1`–`osd6` должны быть разрешены через DNS или `/etc/hosts`. Если используются IP-адреса, замените `osd_hosts` в скрипте:
  ```bash
  osd_hosts=("192.168.1.1" "192.168.1.2" "192.168.1.3" "192.168.1.4" "192.168.1.5" "192.168.1.6")
  ```
- **Права на пинг**: Если `ping` требует привилегий, настройте `sudo` или `setcap`:
  ```bash
  setcap cap_net_raw+ep /bin/ping
  ```
- **Нагрузка на сеть**: Каждый сервер выполняет 5 пингов × 5 серверов = 25 пингов каждые 60 секунд (150 пингов в минуту для 6 серверов). Это приемлемо для небольшого кластера, но для больших кластеров увеличьте интервал до 120 секунд:
  ```xml
  <delay>120</delay>
  ```
- **Ложные срабатывания**: Допуск одной потери пакета снижает ложные срабатывания, но временные сбои сети могут вызвать триггер `Warning`. Для большей надежности можно увеличить порог в скрипте (например, допускать 2 потери: `[ "$ping_result" -lt 3 ]`).
- **Перекрытие триггеров**: Триггеры настроены так, чтобы не перекрываться:
  - `Warning` активен только для 5–15 минут.
  - `Error` активен только для 15–30 минут.
  - `Critical` активен после 30 минут.
  Если проблема устраняется (например, после 20 минут), `Error` деактивируется, и новые триггеры не срабатывают, пока проблема не повторится.
- **Zabbix Agent 1**: Пассивные проверки с интервалом 60 секунд могут задерживать обнаружение проблем. Для более быстрого реагирования уменьшите `<delay>` до 30 секунд, но это увеличит нагрузку на Zabbix сервер.
- **Временные пороги**: Пороги 5, 15 и 30 минут выбраны как разумные. Для других значений (например, 3, 10, 20 минут) замените в выражениях триггеров:
  ```xml
  <expression>{HOST.HOST:net.osd.connectivity.min(3m)}>0 and {HOST.HOST:net.osd.connectivity.min(10m)}=0</expression>
  ```

#### Альтернативный подход
1. **Индивидуальные пинги**:
   - Создать отдельные UserParameters для каждого хоста (например, `net.osd.ping.osd1`, `net.osd.ping.osd2`), возвращающие статус пинга (0=доступен, 1=недоступен).
   - Пример скрипта:
     ```bash
     #!/bin/bash
     host=$1
     ping_result=$(ping -c 5 -W 1 "$host" | grep "received" | awk '{print $4}')
     [ "$ping_result" -lt 4 ] && echo 1 || echo 0
     ```
   - UserParameters:
     ```ini
     UserParameter=net.osd.ping.osd1,/usr/local/bin/osd_monitor/ping_status.sh osd1
     UserParameter=net.osd.ping.osd2,/usr/local/bin/osd_monitor/ping_status.sh osd2
     ```
   - Триггеры для каждого хоста:
     ```xml
     <expression>{osd1:net.osd.ping.osd2.min(5m)}=1 and {osd1:net.osd.ping.osd2.min(15m)}=0</expression>
     ```
   - Недостаток: Требует 5 элементов данных на сервер (30 всего), что усложняет конфигурацию.

2. **Измерение задержек**:
   - Добавить скрипт для возврата средней задержки пинга:
     ```bash
     #!/bin/bash
     host=$1
     ping -c 5 -W 1 "$host" | grep "avg" | awk -F'/' '{print $5}'
     ```
   - UserParameters:
     ```ini
     UserParameter=net.osd.latency.osd1,/usr/local/bin/osd_monitor/ping_latency.sh osd1
     ```
   - Триггер: `{osd1:net.osd.latency.osd2.min(5m)}>100` (задержка >100 мс).
   - Недостаток: Увеличивает объем данных и сложность.

3. **Ceph OSD Perf**:
   - Использовать команду `ceph osd perf` для мониторинга сетевых задержек между OSD:
     ```bash
     ceph --id zabbix-monitor --keyring /etc/ceph/ceph.client.zabbix-monitor.keyring osd perf | grep "apply_latency_ms"
     ```
   - Требует дополнительных прав cephx и парсинга вывода, но может быть менее зависимым от внешних утилит.

#### Дополнительные рекомендации
- **Логирование**: Добавьте в скрипт запись в лог для отладки:
  ```bash
  [ "$ping_result" -lt 4 ] && echo "$(date): $host unreachable ($ping_result/5 packets received)" >> /var/log/osd_connectivity.log
  ```
- **Уведомления**: Настройте действия в Zabbix (**Configuration** > **Actions**) для отправки уведомлений по email или мессенджер при срабатывании триггеров.
- **Дашборд**: Создайте дашборд в Zabbix с графиком `net.osd.connectivity` для каждого OSD хоста, чтобы визуализировать проблемы связности.
- **Тестирование**: Проверьте скрипт вручную:
  ```bash
  sudo -u zabbix /usr/local/bin/osd_monitor/osd_connectivity.sh
  ```
  Симулируйте сбой сети (например, `iptables -A OUTPUT -d 192.168.1.2 -j DROP` для `osd2`) и проверьте срабатывание триггеров через 5, 15 и 30 минут.
- **Пороги**: Если пороги 5/15/30 минут не подходят, настройте их под ваши нужды (например, 3/10/20 минут) в XML:
  ```xml
  <expression>{HOST.HOST:net.osd.connectivity.min(3m)}>0 and {HOST.HOST:net.osd.connectivity.min(10m)}=0</expression>
  ```

#### Заключение
Решение модифицирует мониторинг сетевой связности OSD серверов, используя 5 пингов с допуском одной потери пакета, и добавляет три триггера с разными уровнями серьезности (`Warning`, `Error`, `Critical`) в зависимости от длительности проблемы (5–15, 15–30, 30+ минут). Обновленный скрипт `osd_connectivity.sh` возвращает количество недоступных серверов, а XML-шаблон интегрирует новые триггеры в `Ceph OSD Template`, сохраняя все существующие метрики и триггеры для mon, RadosGW и OSD. Решение надежно, минимизирует ложные срабатывания и легко настраивается под другие временные пороги.

### Key Citations
- [Zabbix Trigger Expressions](https://www.zabbix.com/documentation/current/en/manual/config/triggers/expression)
- [Zabbix Trigger Functions](https://www.zabbix.com/documentation/current/en/manual/config/triggers/trigger_functions)
- [Ceph Network Configuration](https://docs.ceph.com/en/reef/rados/configuration/network-config-ref/)
- [Zabbix User Parameters](https://www.zabbix.com/documentation/current/en/manual/config/items/userparameters)