Для предотвращения утечек данных при развертывании LLM на своих серверах применяются следующие ключевые меры защиты:

## 1. Контроль доступа и аутентификация

- Строгий контроль доступа к моделям и данным с использованием RBAC (контроль доступа на основе ролей) и принципа наименьших привилегий, чтобы только авторизованный персонал имел доступ к LLM и конфиденциальной информации[1][6].
- Надежная аутентификация пользователей и постоянный мониторинг журналов доступа для выявления подозрительной активности[1][6].

## 2. Фильтрация и очистка данных

- Надежная проверка и фильтрация входных данных, включая санитизацию и удаление идентифицируемой информации (например, ФИО, адреса, номера телефонов), чтобы предотвратить попадание конфиденциальных данных в модель[1][5][6].
- Использование методов деперсонализации и автоматического маскирования чувствительных данных перед их обработкой LLM[5].
- Контекстная фильтрация и сегментация входных данных для предотвращения атак типа prompt injection, которые могут привести к утечке данных[1][4].

## 3. Шифрование и защита хранения

- Шифрование данных в состоянии покоя и при передаче (например, TLS для сетевого трафика, шифрование дисков), чтобы защитить данные от несанкционированного доступа[1][6].
- Централизованное и защищенное хранилище моделей с контролем доступа и аудитом операций для предотвращения кражи моделей[1][6].

## 4. Ограничение и мониторинг запросов

- Установка лимитов на количество запросов (rate limiting) для предотвращения DoS-атак и снижения риска утечки данных через частые вызовы модели[1][6].
- Активный мониторинг производительности, журналов и аномалий для выявления подозрительных паттернов и своевременного реагирования на инциденты[1][6].

## 5. Изоляция и ограничение сетевого доступа

- Ограничение доступа LLM к внешним сетевым ресурсам, внутренним API и службам, чтобы минимизировать возможности внешних атак и утечек данных[1][3].
- Разделение компонентов системы на изолированные среды с ограничениями сетевого доступа и строгими политиками безопасности[1].

## 6. Обучение модели на устойчивость к атакам

- Проведение adversarial training (состязательного обучения) для повышения устойчивости модели к попыткам извлечения данных и вредоносным запросам[1][6].
- Использование защитных промптов в Retrieval-Augmented Generation (RAG) системах для предотвращения утечек из контекста[6].

## 7. Внедрение водяных знаков и отслеживание использования

- Интеграция водяных знаков в эмбеддинги и выходные данные модели для идентификации и отслеживания несанкционированного использования моделей[1].

## 8. Обучение и информирование пользователей

- Обучение сотрудников и пользователей мерам безопасности и конфиденциальности при работе с LLM[1].
- Разработка и внедрение политик безопасности и управления данными, включая условия использования и процедуры реагирования на инциденты[1].

---

Эти меры в совокупности обеспечивают комплексную защиту данных при локальном развертывании LLM, минимизируют риски утечек и помогают поддерживать высокий уровень безопасности в корпоративной среде.

[1] https://habr.com/ru/articles/843434/
[2] https://www.unite.ai/ru/%D0%B7%D0%B0%D1%89%D0%B8%D1%82%D0%BD%D1%8B%D0%B5-%D0%BF%D0%BE%D0%B4%D1%81%D0%BA%D0%B0%D0%B7%D0%BA%D0%B8-%D0%BE%D1%82-%D1%83%D1%82%D0%B5%D1%87%D0%B5%D0%BA-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85-llm/
[3] https://www.arcsinus.ru/blog/llm-exposures
[4] https://www.itweek.ru/ai/article/detail.php?ID=228760
[5] https://tenchat.ru/media/2361579-resheniye-problemy-personalnykh-dannykh-pri-rabote-s-vneshnimi-llm
[6] https://habr.com/ru/companies/raft/articles/847152/
[7] https://ya.ru/neurum/c/tehnologii/q/kakie_suschestvuyut_metody_zaschity_dannyh_70db50ef
[8] https://support.catonetworks.com/hc/ru/articles/12635784357405-%D0%9E%D0%B1%D0%B5%D1%81%D0%BF%D0%B5%D1%87%D0%B5%D0%BD%D0%B8%D0%B5-%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D0%B8-%D1%82%D1%80%D0%B0%D1%84%D0%B8%D0%BA%D0%B0-AI-%D0%BF%D1%80%D0%B8%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B9