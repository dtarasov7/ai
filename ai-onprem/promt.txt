Рассмотрим такую ситуацию. Есть некоторая ИТ инфраструктура, в которой развернуты различные opensource продукты. Например ceph, kafka, prometheus, grafana, opensearch, nginx, kubernetes.

Соответственно есть  инвентарь для ansible, в котором перечислены сервера, на которых развернуты эти продукты.

Есть csv файл, в котором указаны версии операционной системы и версии установленного ПО на серверах - далее назовем это "база по версиям".

Задача - с помощью on-premise LLM:

- понимать причины сбоев, на основе данных из логов.

- создавать скрипты/команды для выполнения тех или иных действий.

- отвечать на вопросы по продуктам ( конфигурация, сопровождение, и т.д.)

И все это делать именно в контексте этой самой инфраструктуры. То есть должна использоваться информация из ansible инвентаря и из "базы о версиях".

Решение должно помнить контекст запроса.

Дополнительное условие - в процессе работы нет доступа к интернет, но при настройке решения возможно получение доступа к официальной документации (предварительная загрузка информации) по продуктам , к stackoverflow и т.п. Опиши как конкретно реализовать  такую предварительную загрузку.

Желательно, чтобы модель имела возможность получать обратную связь от пользователя, содержащую информацию о правильности или неправильности преложенного моделью решения.

Какая LLM для этого оптимальней? Как реализовать такое решение? 

Какое требуется оборудование, исходя из ограничения - есть только виртуальные машины без GPU?

Приведи пожалуйста подробное описание.
