### Ответ

**Ключевые моменты:**
- Скрипты для резервного копирования и архивирования объектов из S3-хранилища на базе Ceph 17.2.7 с использованием rclone v1.65.2 созданы.
- Резервное копирование выполняется каждые 30 минут, копируя изменённые объекты в подкаталог с именем `dd-hh-mm` и фиксируя удалённые объекты в файле `dd-hh-mm-deleted.txt`.
- Архивирование запускается в начале каждой декады (1, 11, 21 числа месяца в 00:00), копируя содержимое предыдущего бакета в архивный каталог.
- Оба скрипта создают метрики в формате Prometheus, включающие количество скопированных объектов, время выполнения, объём данных и флаг успешности.
- Скрипты включают проверку на запуск второго экземпляра и ведут логирование.
- Возможные сбои, такие как сетевые ошибки или нехватка места, учтены с предложениями по их обработке.

**Скрипты**
Ниже приведены два Bash-скрипта, которые выполняют задачи резервного копирования и архивирования. Они используют rclone для работы с S3-хранилищем, создают метрики Prometheus и предотвращают одновременный запуск нескольких экземпляров.

**Потенциальные проблемы и решения**
- **Сетевые сбои**: Скрипты могут завершиться с ошибкой при проблемах с сетью. Решение — добавить механизм повторных попыток.
- **Нехватка места**: Недостаток дискового пространства может прервать копирование. Решение — проверка свободного места перед операцией.
- **Большое количество объектов**: Длинный список изменённых объектов может превысить лимит командной строки. Решение — разбивать список на части.
- **Часовые пояса**: Временные метки в S3 хранятся в UTC, что учтено в скриптах.

**Дополнительные метрики**
Для повышения информативности можно добавить метрики, такие как количество ошибок rclone или средний размер скопированного объекта.

---

### Подробный отчёт

```x-shellscript
#!/bin/bash

# Скрипт резервного копирования для S3-хранилища на базе Ceph 17.2.7 с использованием rclone v1.65.2

# Конфигурация
remote="s3backup"  # Имя rclone-ремота (настроен с bucket="")
log_file="/var/log/backup_script.log"
pid_file="/var/run/backup_script.pid"
metrics_dir="/var/log/prometheus"  # Каталог для метрик Prometheus

# Функция логирования
log() {
  echo "$(date +'%Y-%m-%d %H:%M:%S') - $1" >> "$log_file"
}

# Проверка на запуск второго экземпляра
if [ -f "$pid_file" ] && kill -0 $(cat "$pid_file") 2>/dev/null; then
  log "Другой экземпляр уже запущен. Выход."
  exit 1
fi
echo $$ > "$pid_file"

log "Запуск скрипта резервного копирования"

# Определение текущей даты иස

year=$(date +%Y)
month=$(date +%m)
day=$(date +%d)
hour=$(date +%H)
minute=$(date +%M)
second=$(date +%S)

# Вычисление декады (0 для 1-10, 1 для 11-20, 2 для 21-31)
if [ $day -le 10 ]; then
  decade=0
elif [ $day -le 20 ]; then
  decade=1
else
  decade=2
fi

current_bucket="storage-${year}${month}${decade}"
backup_dir_base="storage-${year}${month}${decade}-backup"

# Создание базового каталога для резервных копий, если не существует
mkdir -p "$backup_dir_base"

dd_hh_mm=$(printf "%02d-%02d-%02d" $day $hour $minute)
backup_subdir="$backup_dir_base/$dd_hh_mm"
mkdir -p "$backup_subdir"

# Чтение времени последнего успешного резервного копирования
last_backup_time_file="$backup_dir_base/last_backup_time.txt"
if [ -f "$last_backup_time_file" ]; then
  last_backup_time=$(cat "$last_backup_time_file")
else
  last_backup_time="1970-01-01T00:00:00Z"
fi

# Получение списка текущих объектов
current_list_file="/tmp/current_list_$$.json"
retry=3
for i in $(seq 1 $retry); do
  rclone lsjson "${remote}:${current_bucket}" > "$current_list_file" 2>> "$log_file"
  if [ $? -eq 0 ]; then
    break
  fi
  if [ $i -eq $retry ]; then
    log "Ошибка выполнения rclone lsjson после $retry попыток"
    rm -f "$pid_file"
    exit 1
  fi
  sleep 5
done

# Получение списка объектов из предыдущего запуска
previous_list_file="$backup_dir_base/previous_list.json"
if [ -f "$previous_list_file" ]; then
  previous_keys=$(jq -r '.[].Path' "$previous_list_file" | sort)
else
  previous_keys=""
fi

current_keys=$(jq -r '.[].Path' "$current_list_file" | sort)

# Определение удалённых объектов
deleted_keys=$(comm -23 <(echo "$previous_keys") <(echo "$current_keys"))
if [ -n "$deleted_keys" ]; then
  echo "$deleted_keys" > "$backup_dir_base/$dd_hh_mm-deleted.txt"
fi

# Получение списка изменённых объектов
changed_objects=$(jq -r '[.[] | select(.ModTime > "'$last_backup_time'") | .Path] | .[]' "$current_list_file")
num_copied_objects=$(echo "$changed_objects" | wc -l)

# Копирование изменённых объектов
log_file_rclone="$backup_dir_base/rclone_log_$dd_hh_mm.log"
copy_time=0
total_transferred=0
success=1
if [ -n "$changed_objects" ]; then
  filters=("--filter" "- *")
  for path in $changed_objects; do
    filters+=("--filter" "+ $path")
  done
  start_copy=$(date +%s)
  rclone copy "${remote}:${current_bucket}/" "$backup_subdir/" "${filters[@]}" --stats 1s --transfers 32 --checkers 8 --multi-thread-streams 4 > "$log_file_rclone" 2>&1
  if [ $? -ne 0 ]; then
    log "Ошибка выполнения rclone copy"
    success=0
  else
    end_copy=$(date +%s)
    copy_time=$((end_copy - start_copy))
    total_transferred=$(grep "Transferred" "$log_file_rclone" | awk '{print $2}' | head -1)
    [ -z "$total_transferred" ] && total_transferred=0
  fi
else
  log "Нет изменённых объектов для копирования"
fi

# Сохранение текущего списка для следующего запуска
cp "$current_list_file" "$previous_list_file"

# Сохранение времени текущего запуска
current_time=$(date -u +%Y-%m-%dT%H:%M:%SZ)
echo "$current_time" > "$last_backup_time_file"

# Генерация метрик Prometheus
mkdir -p "$metrics_dir"
metrics_file="$metrics_dir/backup_metrics_$dd_hh_mm.prom"
echo "# HELP s3_backup_copied_objects Количество скопированных объектов" > "$metrics_file"
echo "# TYPE s3_backup_copied_objects gauge" >> "$metrics_file"
echo "s3_backup_copied_objects{dd_hh_mm=\"$dd_hh_mm\"} $num_copied_objects" >> "$metrics_file"

echo "# HELP s3_backup_deleted_objects Количество удалённых объектов" >> "$metrics_file"
echo "# TYPE s3_backup_deleted_objects gauge" >> "$metrics_file"
echo "s3_backup_deleted_objects{dd_hh_mm=\"$dd_hh_mm\"} $(echo "$deleted_keys" | wc -l)" >> "$metrics_file"

echo "# HELP s3_backup_copy_duration_seconds Время копирования в секундах" >> "$metrics_file"
echo "# TYPE s3_backup_copy_duration_seconds gauge" >> "$metrics_file"
echo "s3_backup_copy_duration_seconds{dd_hh_mm=\"$dd_hh_mm\"} $copy_time" >> "$metrics_file"

start_script=$(date +%s)
end_script=$(date +%s)
script_time=$((end_script - start_script))

echo "# HELP s3_backup_script_duration_seconds Общее время выполнения скрипта в секундах" >> "$metrics_file"
echo "# TYPE s3_backup_script_duration_seconds gauge" >> "$metrics_file"
echo "s3_backup_script_duration_seconds{dd_hh_mm=\"$dd_hh_mm\"} $script_time" >> "$metrics_file"

echo "# HELP s3_backup_total_transferred_bytes Общий объём переданных данных в байтах" >> "$metrics_file"
echo "# TYPE s3_backup_total_transferred_bytes gauge" >> "$metrics_file"
echo "s3_backup_total_transferred_bytes{dd_hh_mm=\"$dd_hh_mm\"} $total_transferred" >> "$metrics_file"

echo "# HELP s3_backup_success Флаг успешного выполнения" >> "$metrics_file"
echo "# TYPE s3_backup_success gauge" >> "$metrics_file"
echo "s3_backup_success{dd_hh_mm=\"$dd_hh_mm\"} $success" >> "$metrics_file"

# Очистка
rm -f "$current_list_file"
rm -f "$pid_file"

log "Скрипт резервного копирования завершён"
```

```x-shellscript
#!/bin/bash

# Скрипт архивирования для S3-хранилища на базе Ceph 17.2.7 с использованием rclone v1.65.2

# Конфигурация
remote="s3backup"  # Имя rclone-ремота (настроен с bucket="")
log_file="/var/log/archive_script.log"
pid_file="/var/run/archive_script.pid"
metrics_dir="/var/log/prometheus"  # Каталог для метрик Prometheus

# Функция логирования
log() {
  echo "$(date +'%Y-%m-%d %H:%M:%S') - $1" >> "$log_file"
}

# Проверка на запуск второго экземпляра
if [ -f "$pid_file" ] && kill -0 $(cat "$pid_file") 2>/dev/null; then
  log "Другой экземпляр уже запущен. Выход."
  exit 1
fi
echo $$ > "$pid_file"

log "Запуск скрипта архивирования"

# Определение текущей даты
year=$(date +%Y)
month=$(date +%m)
day=$(date +%d)
hour=$(date +%H)
minute=$(date +%M)

# Проверка, является ли текущий момент началом декады (00:00 1, 11 или 21 числа)
if [ $hour -eq 0 ] && [ $minute -eq 0 ] && ([ $day -eq 1 ] || [ $day -eq 11 ] || [ $day -eq 21 ]); then
  # Вычисление предыдущей декады
  if [ $day -eq 1 ]; then
    prev_month=$(date -d "last month" +%m)
    prev_year=$(date -d "last month" +%Y)
    prev_decade=2
  elif [ $day -eq 11 ]; then
    prev_decade=0
    prev_year=$year
    prev_month=$month
  else  # day == 21
    prev_decade=1
    prev_year=$year
    prev_month=$month
  fi

  prev_bucket="storage-${prev_year}${prev_month}${prev_decade}"
  archive_dir="archive_${prev_bucket}"

  mkdir -p "$archive_dir"

  log "Запуск rclone sync для $prev_bucket в $archive_dir"
  start_time=$(date +%s)
  rclone sync "${remote}:${prev_bucket}/" "$archive_dir/" --transfers 8 --checkers 4 > /tmp/rclone_sync.log 2>&1
  end_time=$(date +%s)
  sync_time=$((end_time - start_time))

  success=1
  if [ $? -ne 0 ]; then
    log "Ошибка выполнения rclone sync"
    success=0
  else
    log "rclone sync успешно завершён"
  fi

  # Генерация метрик Prometheus
  mkdir -p "$metrics_dir"
  dd_hh_mm=$(date +%d-%H-%M)
  metrics_file="$metrics_dir/archive_metrics_$dd_hh_mm.prom"

  total_objects=$(grep "Transferred" /tmp/rclone_sync.log | awk '{print $4}' | head -1)
  [ -z "$total_objects" ] && total_objects=0
  echo "# HELP s3_archive_copied_objects Количество скопированных объектов" > "$metrics_file"
  echo "# TYPE s3_archive_copied_objects gauge" >> "$metrics_file"
  echo "s3_archive_copied_objects{dd_hh_mm=\"$dd_hh_mm\"} $total_objects" >> "$metrics_file"

  echo "# HELP s3_archive_sync_duration_seconds Время синхронизации в секундах" >> "$metrics_file"
  echo "# TYPE s3_archive_sync_duration_seconds gauge" >> "$metrics_file"
  echo "s3_archive_sync_duration_seconds{dd_hh_mm=\"$dd_hh_mm\"} $sync_time" >> "$metrics_file"

  total_transferred=$(grep "Transferred" /tmp/rclone_sync.log | awk '{print $2}' | head -1)
  [ -z "$total_transferred" ] && total_transferred=0
  echo "# HELP s3_archive_total_transferred_bytes Общий объём переданных данных в байтах" >> "$metrics_file"
  echo "# TYPE s3_archive_total_transferred_bytes gauge" >> "$metrics_file"
  echo "s3_archive_total_transferred_bytes{dd_hh_mm=\"$dd_hh_mm\"} $total_transferred" >> "$metrics_file"

  echo "# HELP s3_archive_success Флаг успешного выполнения" >> "$metrics_file"
  echo "# TYPE s3_archive_success gauge" >> "$metrics_file"
  echo "s3_archive_success{dd_hh_mm=\"$dd_hh_mm\"} $success" >> "$metrics_file"

else
  log "Не начало декады или не 00:00. Выход."
fi

rm -f "$pid_file"
log "Скрипт архивирования завершён"
```

#### Настройка rclone
Для работы скриптов необходимо настроить rclone с пустым параметром `bucket` для доступа к различным бакетам. Пример конфигурации:

```bash
[s3backup]
type = s3
provider = Ceph
endpoint = <ваш_эндпоинт_ceph_s3>
access_key_id = <ваш_ключ_доступа>
secret_access_key = <ваш_секретный_ключ>
region =
bucket =
```

Сохраните эту конфигурацию в файле `~/.config/rclone/rclone.conf`.

#### Настройка cron
- **Резервное копирование**: Запустите скрипт каждые 30 минут:
  ```bash
  */30 * * * * /path/to/backup_script.sh
  ```
- **Архивирование**: Запустите скрипт в 00:00 1, 11 и 21 числа каждого месяца:
  ```bash
  0 0 1,11,21 * * /path/to/archive_script.sh
  ```

#### Анализ потенциальных сбоев

| **Сбой** | **Причина** | **Решение** |
|----------|-------------|-------------|
| **Сетевые ошибки** | Проблемы с подключением к S3 или Ceph. | Добавить повторные попытки (до 3 раз с паузой 5 секунд) для команд `rclone lsjson` и `rclone copy/sync`. |
| **Нехватка места** | Недостаток дискового пространства на файловом сервере. | Проверять свободное место перед копированием с помощью `df -k`. |
| **Большое количество объектов** | Список изменённых объектов может превысить лимит командной строки. | Разбивать список на части по 1000 объектов и выполнять несколько команд `rclone copy`. |
| **Часовые пояса** | Временные метки S3 в UTC, локальное время может отличаться. | Использовать UTC для всех временных меток (`date -u`). |
| **Ошибки rclone** | Неправильная конфигурация или временные сбои. | Проверять код возврата rclone и логировать ошибки в `$log_file_rclone`. |

#### Дополнительные метрики
Для повышения информативности можно добавить следующие метрики:
- **s3_backup_error_count**: Количество ошибок, обнаруженных в логе rclone.
- **s3_backup_avg_object_size_bytes**: Средний размер скопированного объекта (total_transferred / num_copied_objects).
- **s3_archive_error_count**: Аналогично для архивирования.

#### Производительность
- **Резервное копирование**: Используются флаги `--transfers 32 --checkers 8 --multi-thread-streams 4` для максимальной производительности.
- **Архивирование**: Используются `--transfers 8 --checkers 4` для щадящего режима, чтобы не перегружать систему во время работы резервного копирования.

#### Логирование
- Логи хранятся в `/var/log/backup_script.log` и `/var/log/archive_script.log`.
- Логи rclone для резервного копирования сохраняются в `$backup_dir_base/rclone_log_$dd_hh_mm.log`.
- Ротация логов осуществляется средствами ОС (например, logrotate).

#### Восстановление
- Для восстановления используйте содержимое каталогов `backup_subdir` в порядке их создания.
- Удалённые объекты указаны в файлах `$dd_hh_mm-deleted.txt`, но их содержимое не сохраняется, что может ограничить восстановление удалённых данных.

#### Рекомендации
- Убедитесь, что на файловом сервере достаточно места для хранения резервных копий и архивов.
- Разместите метрики в каталоге, доступном для Prometheus (например, `/var/log/prometheus`).
- Регулярно проверяйте логи на наличие ошибок и корректируйте конфигурацию при необходимости.

### Ключевые источники
- [Rclone Copy Command Documentation](https://rclone.org/commands/rclone_copy/)
- [Rclone Sync Command Documentation](https://rclone.org/commands/rclone_sync/)
- [Rclone S3 Backend Configuration](https://rclone.org/s3/)
- [Rclone Installation Guide](https://rclone.org/install/)
- [Rclone Changelog](https://rclone.org/changelog/)
- [Rclone v1.65.2 Release Notes](https://forum.rclone.org/t/rclone-v1-65-2-release/44196)
- [Rclone Forum: Incremental Backup Discussion](https://forum.rclone.org/t/can-we-use-rclone-as-incremental-backup-tool/32529)
