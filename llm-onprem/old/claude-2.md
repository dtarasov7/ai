# 10–15 ключевых сценариев применения on-premise LLM для IT и ИБ служб

## **Уровень 1: Базовые сценарии (без RAG и MCP)**

### 1. **Генерация commit messages и changelog**

**Текущая задача/проблема:** Разработчики тратят время на написание информативных commit сообщений, часто делают их неполными или нестандартными.

**Как LLM помогает:** Анализирует diff изменений и автоматически генерирует структурированные commit messages по шаблону (feat/fix/docs/refactor). Интеграция через git hooks или IDE плагины.

**Требования для реализации:** API endpoint LLM, скрипт-обертка для git, настройка pre-commit hook.

**Оценка эффекта:** Экономия 5-10 минут на каждый commit, стандартизация 100% сообщений, улучшение трассировки изменений.

**Пример применения:** При git commit автоматически анализируется diff, LLM предлагает: "fix(ansible): исправлена ошибка в роли nginx при установке сертификатов SSL на CentOS 8".

---

### 2. **Преобразование естественного языка в bash/PowerShell скрипты**

**Текущая задача/проблема:** Инженеры тратят время на поиск синтаксиса команд, написание однотипных скриптов для рутинных операций.

**Как LLM помогает:** Принимает описание задачи на русском языке и генерирует готовый скрипт с комментариями. Пример запроса: "найди все файлы старше 30 дней в /var/log и заархивируй их".

**Требования для реализации:** REST API для LLM, веб-интерфейс или CLI утилита для запросов.

**Оценка эффекта:** Сокращение времени написания скриптов с 30 до 5 минут, снижение синтаксических ошибок на 70%.

**Пример применения:** Дежурный инженер получает скрипт очистки логов с проверками и логированием действий за 30 секунд вместо 20 минут разработки.

---

### 3. **Анализ и объяснение ошибок из логов**

**Текущая задача/проблема:** L1-инженеры тратят 15-30 минут на понимание сложных стектрейсов и ошибок в логах.

**Как LLM помогает:** Получает фрагмент лога с ошибкой, анализирует контекст и выдает: описание проблемы простым языком, вероятные причины, рекомендации по устранению.

**Требования для реализации:** API для отправки логов, интеграция с системой мониторинга (Zabbix/Prometheus).

**Оценка эффекта:** Сокращение времени первичной диагностики с 20 до 3 минут, снижение эскалаций на L2 на 40%.

**Пример применения:** При ошибке "OOMKilled" в Kubernetes, LLM объясняет проблему с памятью, предлагает проверить limits/requests и показывает команды для диагностики.

---

### 4. **Генерация Ansible playbooks из описания задачи**

**Текущая задача/проблема:** Написание Ansible ролей требует знания синтаксиса YAML, модулей, best practices.

**Как LLM помогает:** Преобразует текстовое описание инфраструктурной задачи в готовый playbook с переменными, хендлерами и проверками идемпотентности.

**Требования для реализации:** LLM с fine-tuning на Ansible документации, валидатор YAML синтаксиса.

**Оценка эффекта:** Ускорение создания playbooks с 2 часов до 15 минут, снижение ошибок синтаксиса на 80%.

**Пример применения:** Запрос "установи nginx, настрой виртуальный хост для example.com с SSL от Let's Encrypt" генерирует полноценную роль с tasks, handlers, templates.

---

## **Уровень 2: Сценарии с использованием RAG**

### 5. **Интеллектуальный помощник по внутренней документации**

**Текущая задача/проблема:** Инженеры тратят 30-60 минут на поиск информации в разрозненной документации (Wiki, SharePoint, Git).

**Как LLM помогает:** RAG-база индексирует всю техническую документацию. LLM отвечает на вопросы с указанием источников: "Как настроить VPN для филиала?" → пошаговая инструкция со ссылками.

**Требования для реализации:** Vector DB (Qdrant/Weaviate), индексация документов, веб-интерфейс чата.

**Оценка эффекта:** Сокращение времени поиска информации с 40 до 2 минут, повышение использования документации на 200%.

**Пример применения:** Новый сотрудник получает актуальные инструкции по настройке рабочего места, доступам, стандартам компании через единый интерфейс.

---

### 6. **Анализ уязвимостей кода и конфигураций**

**Текущая задача/проблема:** Ручная проверка кода на уязвимости занимает часы, требует экспертизы ИБ.

**Как LLM помогает:** Анализирует код/конфигурации, сопоставляет с базой OWASP/CWE через RAG. Выдает отчет: найденные уязвимости, критичность, рекомендации по исправлению с примерами.

**Требования для реализации:** RAG-база с CVE/CWE/OWASP, интеграция с Git/CI/CD.

**Оценка эффекта:** Обнаружение 85% типовых уязвимостей, сокращение времени Security Review с 4 часов до 30 минут.

**Пример применения:** При push в Git автоматически проверяется Terraform код на hardcoded credentials, открытые security groups, находятся SQL injections.

---

### 7. **Автоматическая генерация RCA (Root Cause Analysis) для инцидентов**

**Текущая задача/проблема:** Составление RCA отчета после инцидента занимает 2-4 часа, требует сбора данных из разных систем.

**Как LLM помогает:** Собирает данные из систем мониторинга, логов, тикетов через RAG. Генерирует структурированный RCA: хронология, первопричина, влияние, предотвращение повторения.

**Требования для реализации:** RAG с историей инцидентов, интеграция с ITSM, шаблоны RCA.

**Оценка эффекта:** Сокращение времени создания RCA с 3 часов до 30 минут, повышение качества анализа.

**Пример применения:** После сбоя БД автоматически формируется отчет с графиками нагрузки, анализом логов, выводами о причине (deadlock) и планом действий.

---

### 8. **Интеллектуальный классификатор заявок Service Desk**

**Текущая задача/проблема:** Неправильная маршрутизация заявок приводит к потере времени, нарушению SLA.

**Как LLM помогает:** Анализирует текст заявки, историю обращений пользователя через RAG, автоматически: определяет категорию, приоритет, назначает на нужную группу, предлагает решения из KB.

**Требования для реализации:** RAG с базой знаний и историей тикетов, интеграция с ITSM через API.

**Оценка эффекта:** Правильная маршрутизация 92% заявок, сокращение времени первичной обработки с 10 до 1 минуты.

**Пример применения:** Заявка "не работает 1С" автоматически классифицируется, проверяется статус сервисов, предлагается перезапуск клиента или эскалация на команду 1С.

---

## **Уровень 3: Продвинутые сценарии с MCP и сложными интеграциями**

### 9. **Проактивный анализ аномалий в метриках мониторинга**

**Текущая задача/проблема:** Обнаружение нетипового поведения систем происходит post-factum, после жалоб пользователей.

**Как LLM помогает:** Через MCP получает метрики из Prometheus/Zabbix, анализирует паттерны, выявляет аномалии. Генерирует алерты с объяснением: "Необычный рост latency на 300% для API gateway, вероятна проблема с upstream сервисом".

**Требования для реализации:** MCP серверы для систем мониторинга, обучение модели на исторических данных.

**Оценка эффекта:** Обнаружение 70% проблем до влияния на пользователей, сокращение MTTR на 40%.

**Пример применения:** LLM обнаруживает постепенную деградацию производительности БД за 2 часа до критического порога и инициирует превентивные меры.

---

### 10. **Автоматическое создание архитектурных диаграмм из описания**

**Текущая задача/проблема:** Создание и актуализация диаграмм архитектуры занимает часы, часто устаревают.

**Как LLM помогает:** Принимает текстовое описание или анализирует IaC код (Terraform), генерирует диаграммы в PlantUML/Mermaid формате. Через MCP может обращаться к реальной инфраструктуре для актуализации.

**Требования для реализации:** MCP для доступа к IaC репозиториям, рендерер диаграмм.

**Оценка эффекта:** Сокращение времени создания диаграмм с 3 часов до 10 минут, автоматическая актуализация.

**Пример применения:** При изменении Terraform кода автоматически обновляется диаграмма сетевой топологии с VPC, подсетями, security groups.

---

### 11. **Интеллектуальный помощник дежурного инженера**

**Текущая задача/проблема:** Дежурный получает множество алертов, сложно приоритизировать и понять взаимосвязи.

**Как LLM помогает:** Через MCP подключается ко всем системам (мониторинг, логи, CMDB). Коррелирует алерты, предлагает: порядок действий, проверочные команды, вероятные причины, ссылки на runbook.

**Требования для реализации:** MCP адаптеры для всех систем, база runbooks в RAG, интерактивный чат.

**Оценка эффекта:** Сокращение времени реакции на инциденты с 15 до 5 минут, снижение ошибок при устранении на 60%.

**Пример применения:** При алерте "Database connection pool exhausted" LLM анализирует нагрузку, находит проблемный сервис, предлагает рестарт и оптимизацию пула.

---

### 12. **Автоматизация Security Operations (SOC)**

**Текущая задача/проблема:** Аналитики SOC тратят 70% времени на рутинный анализ событий безопасности.

**Как LLM помогает:** Через MCP получает события из SIEM, анализирует с учетом threat intelligence из RAG. Автоматически: триажирует инциденты, enrichment данных (GeoIP, репутация), генерирует отчеты для расследования.

**Требования для реализации:** MCP для SIEM, RAG с IOC/threat feeds, playbooks для реагирования.

**Оценка эффекта:** Автоматическая обработка 80% false-positive, сокращение времени расследования с 2 часов до 20 минут.

**Пример применения:** При детектировании подозрительной активности LLM проверяет репутацию IP, анализирует поведение пользователя, определяет legitimate/malicious.

---

### 13. **Генерация и валидация IaC кода с учетом стандартов компании**

**Текущая задача/проблема:** Инженеры создают инфраструктуру, не всегда соблюдая корпоративные стандарты и best practices.

**Как LLM помогает:** Генерирует Terraform/CloudFormation код по описанию, проверяет существующий код на соответствие политикам через RAG (naming conventions, тегирование, security). Через MCP может проверять состояние в реальном облаке.

**Требования для реализации:** RAG с корпоративными стандартами, MCP для cloud providers, Policy as Code.

**Оценка эффекта:** 100% соответствие стандартам, сокращение review циклов с 3 до 1, предотвращение security misconfigurations.

**Пример применения:** При создании EC2 инстанса автоматически применяются правильные теги, security groups, подсети согласно стандартам.

---

### 14. **Оптимизация использования ресурсов и cost management**

**Текущая задача/проблема:** Перерасход бюджета на инфраструктуру из-за неоптимального использования ресурсов.

**Как LLM помогает:** Через MCP анализирует метрики использования (CPU, RAM, Storage), сопоставляет с биллингом. Предлагает: rightsizing рекомендации, выявляет zombie resources, генерирует отчеты по cost centers.

**Требования для реализации:** MCP для cloud billing APIs, метрик мониторинга, исторические данные в RAG.

**Оценка эффекта:** Снижение расходов на инфраструктуру на 20-30%, автоматическое выявление неиспользуемых ресурсов.

**Пример применения:** LLM обнаруживает, что 40% виртуальных машин используют менее 10% CPU и предлагает downgrade с экономией 15000$/месяц.

---

### 15. **Интеллектуальная система управления изменениями (Change Management)**

**Текущая задача/проблема:** Оценка рисков изменений происходит субъективно, часто приводит к инцидентам.

**Как LLM помогает:** Анализирует RFC (Request for Change), через MCP проверяет: зависимости в CMDB, историю инцидентов для затрагиваемых систем, конфликты в календаре изменений. Генерирует: оценку риска, rollback план, чек-листы проверок.

**Требования для реализации:** MCP для ITSM/CMDB, RAG с историей изменений и инцидентов, интеграция с CAB процессом.

**Оценка эффекта:** Снижение failed changes на 50%, сокращение времени оценки RFC с 30 до 5 минут, предотвращение конфликтов изменений.

**Пример применения:** При планировании обновления БД, LLM выявляет зависимые сервисы, предупреждает о maintenance window другой критичной системы, предлагает оптимальное время.

---

## Приоритеты внедрения

**Фаза 1 (Quick wins, 1-2 месяца):** Сценарии 1-4 - не требуют сложной инфраструктуры, дают быстрый эффект.

**Фаза 2 (RAG foundation, 3-4 месяца):** Сценарии 5-8 - требуют построения RAG инфраструктуры, но дают значительный эффект.

**Фаза 3 (Advanced automation, 6+ месяцев):** Сценарии 9-15 - требуют глубокой интеграции через MCP, но обеспечивают максимальную автоматизацию.

Рекомендуется начать с GigaChat или аналогичных российских моделей для соответствия требованиям по локализации данных, с возможностью последующего добавления специализированных моделей для конкретных задач.
