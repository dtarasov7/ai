**Роль:** эксперт по автоматизации инфраструктурных команд и внедрению on-premise LLM

**Цель:** выявить и описать 15–20 ключевых сценариев, где on-premise open-source LLM улучшает эффективность внутренней IT-службы и службы ИБ (SOC).
  Примерный список областей: 
  * проектирование решений 
  * сравнение вариантов решений
  * анализ решений, программного кода с точки зрения ИБ
  * проектирование, анализ и документирование процессов
  * разработка/доработка/анализ скриптов, ansible ролей pipelines и др.
  * мониторинг (анализ на не типовое потребление ресурсов и др. )
  * логирование (анализ сообщений об ошибках и предупреждениях и др.)
  * документирование (формирование commit message, changelog, построение архитектурных и сетевых диаграмм, описание решений, ansible скриптов и др.)
  * Подготовка инструкций
  * инциденты и проблемы
  * заявки и обращения

  Если один и тот же сценарий можно выполнить как с RAG/MCP так и без них (с разной эффективностью), то приведи оба варианта.

**Контекст:**

* Рассматриваем как только LLM, так и LVV c расширениями с помощью RAG и MCP
* RAG-база (если используется) может быть предварительно наполнена документацией из открытых источников.
* Используются только локальные модели (например, LLaMA, Mistral, Falcon, DeepSeek и т.п.) и open-source инфраструктура. 
  Приоритет в использовании российских моделей (gigaChat и ее производных).
* Нужен строгий контроль ролей/прав и журналирование действий.
* В IT-службе для автоматизации НЕ используется n8n, chef, puppet.
* База тикетов/инцидентов - отсутствует


**Формат вывода:**
Создай **карточки сценариев**, каждая из которых включает:

1. **Название сценария.**
2. **Текущая задача, проблема или узкое место.**
3. **Как LLM помогает:** механизм, примеры запросов, интеграции.
4. **Требуется ли для реализации:** подключение источников знаний, API, форматы данных.
5. **Оценка эффекта:** сокращение времени, снижение нагрузки на инженеров, уменьшение ошибок, улучшение SLA.
6. **Пример реального применения или типовой use case.**

Сценарии должны сортироваться по мере возрастания трудности их внедрения. Первыми рассматриваются сценарии не требующие ни RAG ни MCP

Для сценариев БЕЗ RAG и БЕЗ МCP расписать конкретную архитектуру решения:
* какую open-source LLM-платформу
* как организовать RBAC и журналирование
* дать оценку требуемого оборудования из расчет 10 одновременных пользователей 
  с требуемым минимальной скоростью вывода 30 токенов/сек и контекстом 8000 для двух вариантов - c HA и без HA

**Критерии качества:**

* Упор на реальную автоматизацию, повышение эффективности операций, снижение трудозатрат.
* Практический язык: понятен инженеру, архитектору, специалисту по ИБ, руководителю IT-службы.

**Самопроверка перед выдачей:**

* Все ли карточки объясняют пользу и шаги внедрения?
* Оценка эффекта присутствует в каждой карточке.
