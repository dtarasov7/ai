Ниже я опишу, как построить дашборд в Grafana для мониторинга общего статуса информационной системы (ИС). Дашборд будет содержать по одной панели типа "Stat" (или "Gauge" с текстовым отображением статуса) для каждого типа компонента. Каждая панель будет отображать совокупный статус компонента: 

- **ok** (зеленый цвет, текст "OK" или иконка) — все экземпляры компонента работают без замечаний (100% доступны и здоровы).
- **warning** (желтый цвет, текст "WARNING" или иконка) — есть нефатальные проблемы (например, один или несколько экземпляров недоступны, но общий компонент частично работает; или наблюдаются повышенные ошибки/задержки, но не критичные).
- **error** (красный цвет, текст "ERROR" или иконка) — компонент не работает (все экземпляры недоступны или критичные сбои).

### Общие принципы настройки дашборда в Grafana
- **Источник данных**: Prometheus (версия 2.31).
- **Панели**: Для каждой панели используйте тип "Stat". В запросе (PromQL) вычислите числовое значение статуса (например, 2 для ok, 1 для warning, 0 для error). Затем настройте "Value mappings" в панели:
  - 2 → "OK" (зеленый).
  - 1 → "WARNING" (желтый).
  - 0 → "ERROR" (красный).
- **Агрегация статуса**: Статус вычисляется на основе метрик доступности (up/down), здоровья (health checks) и производительности (ошибки, задержки). Используйте PromQL для агрегации (например, `count(up == 1)` для подсчета работающих экземпляров).
- **Сбор метрик**:
  - Установите Node Exporter на все хосты для базовых метрик (up/down, CPU/memory/disk).
  - Используйте Blackbox Exporter для внешних проверок доступности (HTTP/TCP-пинги) — особенно для компонентов, доступных через интернет (nginx в DMZ) или внутреннюю сеть.
  - Для специфических сервисов используйте соответствующие экспортеры (см. ниже). Все экспортеры настраиваются в Prometheus как jobs в конфигурации (prometheus.yml).
  - Период сбора: 15-30 секунд для большинства метрик.
  - Доступность: Для внешних пользователей проверяйте через Blackbox с интернет-точки обзора; для внутренних — с внутренней сети.
- **Общие метрики для всех**:
  - `up{job="<job_name>"}`: 1 если экземпляр доступен, 0 если нет.
  - Дополнительно: `node_cpu_usage`, `node_memory_usage`, `node_disk_usage` из Node Exporter для выявления ресурсных проблем (warning, если >80%).
- **Вычисление статуса в PromQL**:
  - Определите общее количество экземпляров (total_instances) как константу или count(label).
  - Пример запроса: `clamp_max(min((count(up{job="<job_name>"} == 1) / <total_instances>) * 2, 2)` — возвращает 2 (ok) если все up, 1 (warning) если частично, 0 (error) если ничего.
  - Уточняйте для каждого компонента (добавляйте health-метрики).

Теперь разберем по компонентам. Для каждого указано:
- Метрики для сбора.
- Инструменты/экспортеры.
- PromQL для вычисления совокупного статуса (адаптируйте под реальные job_names и total_instances).

### 1. nginx в DMZ (несколько эквивалентных серверов, доступ через интернет)
- **Метрики**: `up` (доступность), `nginx_http_requests_total` (кол-во запросов), `nginx_http_response_time_seconds` (время ответа), `nginx_http_response_status` (статусы ответов, ошибки если >5% 5xx), `node_cpu_usage` (ресурсы хоста).
- **Сбор**: 
  - Nginx Prometheus Exporter (или встроенный /metrics endpoint в nginx с модулем prometheus-nginx).
  - Blackbox Exporter для внешней проверки (HTTP-пинг на публичный URL, проверка SSL и ответа 200 OK).
  - Node Exporter на хостах.
- **Вычисление статуса**:
  - ok: Все серверы up, <1% ошибок 5xx, время ответа <500ms, Blackbox проверка проходит для всех.
  - warning: 1+ сервер down или >1% ошибок/задержек, но хотя бы один up.
  - error: Все down или Blackbox не проходит (ИС недоступна для пользователей).
  - PromQL: `clamp_max(min((count(up{job="nginx_dmz"} == 1 and blackbox_http_status_code == 200) / <total_nginx_dmz>) * 2 - (sum(nginx_http_response_status{status=~"5.."})/sum(nginx_http_requests_total) > 0.01), 2)`.

### 2. Серверы приложений (AS) (несколько эквивалентных серверов)
- **Метрики**: `up` (доступность хоста), `node_cpu_usage`, `node_memory_usage`, `node_disk_usage` (ресурсы), `process_resident_memory_bytes` (память процессов).
- **Сбор**: Node Exporter на каждом AS. Если AS — это Java/.NET приложения, добавьте JMX Exporter или встроенный Prometheus client для app-метрик.
- **Вычисление статуса**:
  - ok: Все AS up, ресурсы <80%.
  - warning: 1+ AS down или ресурсы >80%, но хотя бы один up.
  - error: Все down.
  - PromQL: `clamp_max(min((count(up{job="app_servers"} == 1 and node_cpu_usage < 0.8 and node_memory_usage < 0.8) / <total_as>) * 2, 2)`.

### 3. Микросервисы (по одному экземпляру на каждом AS)
- **Метрики**: `up` (доступность), `http_requests_total` (запросы), `http_response_time_seconds` (задержки), `http_errors_total` (ошибки), кастомные метрики приложения (если есть).
- **Сбор**: Встроенный Prometheus client в микросервисах (например, Spring Boot Actuator или Micrometer для Java; аналогично для других языков). Blackbox Exporter для внутренних HTTP-пингов (через nginx на AS).
- **Вычисление статуса**:
  - ok: Все экземпляры up, <1% ошибок, задержки <200ms.
  - warning: 1+ down или повышенные ошибки/задержки, но хотя бы один up.
  - error: Все down.
  - PromQL: `clamp_max(min((count(up{job="microservices"} == 1 and http_errors_total / http_requests_total < 0.01) / <total_microservices>) * 2, 2)`.

### 4. nginx на AS (маршрутизирует к микросервисам, на каждом AS)
- **Метрики**: Аналогично nginx в DMZ: `up`, `nginx_http_requests_total`, `nginx_http_response_time_seconds`, `nginx_http_response_status`.
- **Сбор**: Nginx Prometheus Exporter. Blackbox Exporter для внутренних проверок (TCP/HTTP на локальный порт).
- **Вычисление статуса**:
  - ok: Все экземпляры up, <1% ошибок.
  - warning: 1+ down или ошибки, но хотя бы один up.
  - error: Все down (микросервисы недоступны внутри AS).
  - PromQL: `clamp_max(min((count(up{job="nginx_as"} == 1 and sum(nginx_http_response_status{status=~"5.."})/sum(nginx_http_requests_total) < 0.01) / <total_nginx_as>) * 2, 2)`.

### 5. Кластер серверов с Redis
- **Метрики**: `up`, `redis_connected_clients`, `redis_used_memory`, `redis_commands_processed_total`, `redis_cluster_state` (здоровье кластера), `redis_errors_total`.
- **Сбор**: Redis Exporter (поддерживает кластеры).
- **Вычисление статуса**:
  - ok: Все ноды up, кластер state=ok, ошибки=0.
  - warning: 1+ нода down или повышенная память/ошибки, но кластер state=ok.
  - error: Все down или state=fail.
  - PromQL: `clamp_max(min((count(up{job="redis"} == 1 and redis_cluster_state == 1) / <total_redis_nodes>) * 2 - (redis_errors_total > 0), 2)`.

### 6. Кластер серверов с RabbitMQ
- **Метрики**: `up`, `rabbitmq_queue_messages`, `rabbitmq_node_up`, `rabbitmq_cluster_size`, `rabbitmq_erlang_processes` (ресурсы), `rabbitmq_errors`.
- **Сбор**: RabbitMQ Prometheus Exporter (встроенный в новые версии или отдельный плагин).
- **Вычисление статуса**:
  - ok: Все ноды up, cluster_size=total, ошибки=0.
  - warning: 1+ нода down, но cluster_size>0.
  - error: Все down или cluster_size=0.
  - PromQL: `clamp_max(min((count(up{job="rabbitmq"} == 1 and rabbitmq_node_up == 1) / <total_rabbitmq_nodes>) * 2 - (rabbitmq_errors > 0), 2)`.

### 7. Кластер серверов с Kafka + Zookeeper
- **Метрики**: `up`, `kafka_broker_status` (для Kafka), `zookeeper_server_state` (для Zookeeper), `kafka_topic_partition_under_replicated` (репликация), `kafka_consumer_lag` (задержки), ошибки.
- **Сбор**: Kafka Exporter (для Kafka), Zookeeper Exporter (для ZK).
- **Вычисление статуса**:
  - ok: Все ноды up, state=leader/follower, under_replicated=0.
  - warning: 1+ нода down или under_replicated>0, но кластер работает.
  - error: Все down или state=down.
  - PromQL: `clamp_max(min((count(up{job="kafka"} == 1 and kafka_broker_status == 1 and count(up{job="zookeeper"} == 1 and zookeeper_server_state == 1) / (<total_kafka_nodes> + <total_zk_nodes>)) * 2 - (kafka_topic_partition_under_replicated > 0), 2)`.

### 8. Кластер серверов с Postgres
- **Метрики**: `up`, `pg_up`, `pg_replication_lag_seconds`, `pg_connections`, `pg_errors`, `pg_database_size`.
- **Сбор**: Postgres Exporter (поддерживает кластеры с репликацией).
- **Вычисление статуса**:
  - ok: Все ноды up, lag<10s, ошибки=0.
  - warning: 1+ нода down или lag>10s, но primary up.
  - error: Все down.
  - PromQL: `clamp_max(min((count(pg_up{job="postgres"} == 1) / <total_pg_nodes>) * 2 - (pg_replication_lag_seconds > 10 or pg_errors > 0), 2)`.

### 9. Кластер серверов с Keycloak
- **Метрики**: `up`, `keycloak_realm_users`, `keycloak_login_errors`, `keycloak_response_time`, `jvm_memory_used_bytes` (если на Java).
- **Сбор**: Keycloak имеет встроенный /metrics endpoint (с версии 12+). Альтернатива: JMX Exporter для Java-метрик.
- **Вычисление статуса**:
  - ok: Все ноды up, ошибки=0.
  - warning: 1+ нода down или ошибки>0, но хотя бы одна up.
  - error: Все down.
  - PromQL: `clamp_max(min((count(up{job="keycloak"} == 1 and keycloak_login_errors == 0) / <total_keycloak_nodes>) * 2, 2)`.

### 10. Кластер серверов с Consul
- **Метрики**: `up`, `consul_health_node_status` (critical=0, warning<total), `consul_peers`, `consul_leader` (лидер есть).
- **Сбор**: Consul Exporter.
- **Вычисление статуса**:
  - ok: Все ноды up, health=passing, лидер есть.
  - warning: 1+ нода warning или нет лидера, но peers>0.
  - error: Все down или health=critical.
  - PromQL: `clamp_max(min((count(up{job="consul"} == 1 and consul_health_node_status == 1) / <total_consul_nodes>) * 2 - (consul_leader == 0), 2)`.

### 11. Кластер серверов с Ceph
- **Метрики**: `up`, `ceph_health_status` (0=HEALTH_OK), `ceph_osd_up`, `ceph_pg_active_clean` (чистые PG), ошибки.
- **Сбор**: Ceph Prometheus Exporter (встроенный в Ceph).
- **Вычисление статуса**:
  - ok: health=0, все OSD up.
  - warning: health=1 (warn) или 1+ OSD down, но health!=2.
  - error: health=2 (err) или все down.
  - PromQL: `clamp_max(min((count(up{job="ceph"} == 1 and ceph_osd_up == 1) / <total_ceph_nodes>) * 2 - (ceph_health_status > 0), 2)` (адаптировать: если health=0 → +2, =1 → +1, =2 → 0).

### 12.
