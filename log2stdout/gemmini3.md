Это классическая задача построения надежного пайплайна доставки логов (Log Shipping). Учитывая вводные данные, главной сложностью является разделение потоков: чтобы системные логи шли своим чередом, а логи приложений уходили в Vector и на srv1, минуя локальные файлы.

Ниже приведен анализ возможных архитектур и итоговая **рекомендованная реализация**.

---

### Архитектурные варианты

#### Вариант 1: Vector как основной маршрутизатор (Рекомендуемый)
**Схема:** `Systemd -> Journald -> Vector (Disk Buffer) -> Kafka & srv1`
**Rsyslog:** Настраивается на *игнорирование* сервисов приложений.

В этом варианте Vector самостоятельно читает журнал, буферизирует данные на диске и рассылает их получателям. Rsyslog остается только для системных нужд.

*   **Плюсы:**
    *   **Надежность:** Vector имеет отличные механизмы `disk buffer`, переживающие перезагрузку.
    *   **Изоляция:** Логи приложений не нагружают Rsyslog.
    *   **Гибкость:** Vector лучше работает с JSON/структурированными логами для Kafka.
*   **Минусы:**
    *   Нужно настроить Vector на отправку по протоколу Syslog (udp/tcp) на srv1 (это штатная функция).

#### Вариант 2: Rsyslog как маршрутизатор
**Схема:** `Systemd -> Journald -> Rsyslog -> (Local Socket) -> Vector -> Kafka`
**Rsyslog:** Отправляет на srv1, пишет в сокет Vector'а и делает `stop`, чтобы не писать в `/var/log/messages`.

*   **Плюсы:**
    *   Rsyslog уже настроен на отправку в srv1.
*   **Минусы:**
    *   **Риск потери:** Если Vector упадет или Kafka будет недоступна, Rsyslog должен уметь буферизировать отправку в Vector (модуль `omfwd` с очередью на диске). Настройка очередей в Rsyslog сложнее и менее прозрачна, чем в Vector.
    *   **Сложность конфига:** Rsyslog конфигурация становится запутанной (нужны условия фильтрации, правила исключения).

---

### Рекомендованная реализация (Вариант 1)

Мы будем использовать Vector для чтения journald, буферизации и отправки. Rsyslog мы "попросим" не трогать эти сервисы.

Предположим, ваши сервисы называются `app-backend.service` и `app-worker.service`.

#### Шаг 1: Настройка Rsyslog (Исключение из /var/log/messages)

Чтобы логи не попадали в `/var/log/messages` и не дублировались Rsyslog-ом на `srv1` (так как Vector сам отправит их туда), нужно добавить правило фильтрации в начало конфигурации (обычно `/etc/rsyslog.d/00-ignore-apps.conf` или в начало `rsyslog.conf`).

```bash
# /etc/rsyslog.d/01-block-apps.conf

# Если имя программы (tag) совпадает с именами ваших сервисов - отбрасываем
# systemd обычно использует имя юнита или имя процесса как programname
:programname, isequal, "app-backend"stop
:programname, isequal, "app-worker" stop

# Альтернативный вариант фильтрации по свойствам systemd (если доступно):
# if $!_SYSTEMD_UNIT == 'app-backend.service' then stop
```

*После этого перезапустите rsyslog.* Теперь логи приложений есть только в `journald`, но не в текстовых файлах.

#### Шаг 2: Настройка Vector

Вам потребуется конфигурация с **дисковым буфером** (Disk Buffer). Это ключевой момент для защиты от потери данных при недоступности Kafka (часы) и рестарте хоста.

Файл `/etc/vector/vector.toml` (или `.yaml`):

```toml
# 1. Источник: Читаем Systemd Journal
[sources.app_logs_journal]
type = "journald"
# Читаем только конкретные юниты
include_units = ["app-backend.service", "app-worker.service"] 
# Можно начать с текущего момента или с конца
current_boot_only = true 

# 2. Трансформация (опционально): Парсинг JSON, добавление полей
[transforms.parse_logs]
type = "remap"
inputs = ["app_logs_journal"]
source = '''
  # Если приложение пишет JSON в stdout, распарсим его
  . = parse_json(.message) ?? . 
  .host = get_hostname!() 
'''

# 3. Синк: Kafka (с защитой от сбоев)
[sinks.to_kafka]
type = "kafka"
inputs = ["parse_logs"]
bootstrap_servers = "kafka-broker:9092"
topic = "app-logs"
encoding.codec = "json"

  # --- ЗАЩИТА ОТ ПОТЕРИ ДАННЫХ ---
  [sinks.to_kafka.buffer]
  type = "disk"                     # Используем диск, а не память
  max_size = 5368709120             # Например, 5 ГБ (рассчитайте под ваш объем за N часов)
  data_dir = "/var/lib/vector/kafka_buffer" # Директория должна сохраняться при ребуте

# 4. Синк: Syslog Server (srv1)
[sinks.to_srv1]
type = "socket" # Или используйте type = "syslog" для строгого RFC
inputs = ["parse_logs"]
address = "srv1:514"
mode = "tcp" # Или udp
encoding.codec = "text" # Или "syslog" если нужен формат RFC5424

  # Также буферизируем, если сеть до srv1 упадет
  [sinks.to_srv1.buffer]
  type = "disk"
  max_size = 1073741824 # 1 ГБ
  data_dir = "/var/lib/vector/syslog_buffer"
```

### Почему это решение надежно?

1.  **Systemd Journal как первичный буфер:**
    Если Vector упадет или будет остановлен, логи продолжат копиться в системном журнале (`/var/log/journal`). При старте Vector дочитает их (благодаря чекпоинтам).
    *Важно:* Убедитесь, что `/etc/systemd/journald.conf` имеет достаточный `SystemMaxUse` (например, 4G), чтобы journald не ротировал файлы слишком быстро, пока Vector лежит.

2.  **Vector Disk Buffer:**
    Если Kafka недоступна, Vector будет писать логи в `/var/lib/vector/kafka_buffer`.
    *   При рестарте сервера: Файлы на диске сохраняются. При старте Vector считает их и продолжит отправку.
    *   При переполнении диска: Можно настроить поведение `drop_newest` или блокировку чтения (backpressure), чтобы не потерять старые важные логи.

3.  **Исключение из messages:**
    Правило `stop` в Rsyslog гарантирует чистоту `/var/log/messages` и отсутствие двойной отправки, если бы Rsyslog тоже пытался слать это на srv1.

### Сравнение с альтернативами

| Характеристика | Вариант Vector (Рекомендованный) | Вариант Rsyslog-only | Вариант "Гибрид" |
| :--- | :--- | :--- | :--- |
| **Путь логов** | Journald -> Vector | Journald -> Rsyslog | Journald -> Rsyslog -> Vector |
| **Защита при падении Kafka** | **Высокая** (Vector Disk Buffer) | **Средняя** (Rsyslog Disk Queue сложнее в настройке) | **Высокая** (Vector Disk Buffer) |
| **Исключение из /var/log/messages** | Требуется конфиг Rsyslog (stop) | Требуется конфиг Rsyslog | Требуется конфиг Rsyslog |
| **Нагрузка на CPU** | Низкая (Rust, эффективный) | Средняя/Высокая (при сложном парсинге) | Средняя (два агента обрабатывают лог) |
| **Удобство работы с JSON** | Отличное (VRL) | Посредственное (Rainerscript) | Отличное |
| **Риск потери при ребуте** | Минимальный | Минимальный (если настроены Disk Queues) | Минимальный |

### Резюме
Используйте **Vector** для чтения `journald` напрямую.
1. Добавьте `stop` правило в **Rsyslog** для ваших сервисов.
2. Включите `buffer.type = "disk"` в **Vector** для Kafka sink.
3. Отправляйте логи на `srv1` средствами **Vector** (sink socket/syslog), чтобы централизовать управление потоками данных приложений в одном месте.
