**Роль:** эксперт по автоматизации инфраструктурных команд и внедрению on-premise LLM с Retrieval-Augmented Generation (RAG).

**Цель:** выявить и описать 10–15 ключевых сценариев, где on-premise open-source LLM с RAG улучшает эффективность внутренней IT-службы.

**Контекст:**

* IT-служба обслуживает: Linux, Redis, RabbitMQ, OpenSearch, Prometheus, Grafana, Ansible, Nginx, HAProxy, Ceph, Kubernetes, Deckhouse, Dataprepper, OpenTelemetry Collector.
* RAG-база может быть предварительно наполнена документацией из открытых источников.
* Используются только локальные модели (например, LLaMA, Mistral, Falcon, DeepSeek и т.п.) и open-source инфраструктура.

**Формат вывода:**
Создай 10–15 **карточек сценариев**, каждая из которых включает:

1. **Название сценария.**
2. **Текущая проблема или узкое место.**
3. **Как LLM+RAG помогает:** механизм, примеры запросов, интеграции.
4. **Что требуется для реализации:** подключение источников знаний, API, форматы данных.
5. **Оценка эффекта:** сокращение времени, снижение нагрузки на инженеров, уменьшение ошибок, улучшение SLA.
6. **Пример реального применения или типовой use case.**

**Критерии качества:**

* Конкретность и применимость к указанным системам.
* Упор на реальную автоматизацию и снижение трудозатрат.
* Практический язык: понятен архитектору или руководителю IT-службы.
* Разнообразие областей: мониторинг, инциденты, обновления, документация, обучение персонала и т.д.

**Самопроверка перед выдачей:**

* Есть ли сценарии для разных аспектов поддержки (операции, инциденты, настройка, аналитика)?
* Все ли карточки объясняют пользу и шаги внедрения?
* Оценка эффекта присутствует в каждой карточке.

**Если данных не хватает:** уточни у пользователя, какие метрики эффективности приоритетны (время, SLA, количество обращений, стоимость).


Посчитай стоимость и тип оборудования исходя из 10 одновременных запросов и скорости инференса не более 100 токенов в секунду. Оптмальное LLM и ПО выбери самостоятельно

100 ток/с - это минимум на каждый их 10 запросов
контекст 4k
Необходимо учитывать требование high avail
